{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tx-Z2IAVPchr",
        "outputId": "23ef6400-3301-4e0a-e1a8-811abd553a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML-for-context'...\n",
            "remote: Enumerating objects: 236, done.\u001b[K\n",
            "remote: Counting objects: 100% (236/236), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 236 (delta 122), reused 222 (delta 108), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (236/236), 126.74 KiB | 1.15 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n",
            "/content/ML-for-context\n",
            "Requirement already satisfied: aiohappyeyeballs==2.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.6.1)\n",
            "Collecting aiohttp==3.12.15 (from -r requirements.txt (line 2))\n",
            "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: aiosignal==1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: anyio==4.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.11.0)\n",
            "Collecting attrs==25.3.0 (from -r requirements.txt (line 6))\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi==2025.8.3 (from -r requirements.txt (line 7))\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting charset-normalizer==3.4.3 (from -r requirements.txt (line 8))\n",
            "  Downloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Requirement already satisfied: click==8.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (8.3.0)\n",
            "Collecting datasets==4.1.1 (from -r requirements.txt (line 10))\n",
            "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting dill==0.4.0 (from -r requirements.txt (line 11))\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fastapi==0.118.0 (from -r requirements.txt (line 12))\n",
            "  Downloading fastapi-0.118.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting filelock==3.19.1 (from -r requirements.txt (line 13))\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting frozenlist==1.7.0 (from -r requirements.txt (line 14))\n",
            "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting fsspec==2025.9.0 (from -r requirements.txt (line 15))\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting grpcio==1.75.1 (from -r requirements.txt (line 16))\n",
            "  Downloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: h11==0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (0.16.0)\n",
            "Requirement already satisfied: h2==4.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (4.3.0)\n",
            "Collecting hf-xet==1.1.10 (from -r requirements.txt (line 19))\n",
            "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: hpack==4.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (4.1.0)\n",
            "Requirement already satisfied: httpcore==1.0.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (1.0.9)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (0.28.1)\n",
            "Collecting huggingface-hub==0.35.3 (from -r requirements.txt (line 23))\n",
            "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: hyperframe==6.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (6.1.0)\n",
            "Collecting idna==3.10 (from -r requirements.txt (line 25))\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 26)) (3.1.6)\n",
            "Requirement already satisfied: joblib==1.5.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (1.5.2)\n",
            "Requirement already satisfied: MarkupSafe==3.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (3.0.3)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (1.3.0)\n",
            "Collecting multidict==6.6.4 (from -r requirements.txt (line 30))\n",
            "  Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: multiprocess==0.70.16 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 31)) (0.70.16)\n",
            "Requirement already satisfied: networkx==3.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 32)) (3.5)\n",
            "Collecting numpy==2.3.3 (from -r requirements.txt (line 33))\n",
            "  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging==25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 34)) (25.0)\n",
            "Collecting pandas==2.3.3 (from -r requirements.txt (line 35))\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow==11.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 36)) (11.3.0)\n",
            "Collecting portalocker==3.2.0 (from -r requirements.txt (line 37))\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting propcache==0.3.2 (from -r requirements.txt (line 38))\n",
            "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting protobuf==6.32.1 (from -r requirements.txt (line 39))\n",
            "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting pyarrow==21.0.0 (from -r requirements.txt (line 40))\n",
            "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pydantic==2.11.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 41)) (2.11.10)\n",
            "Requirement already satisfied: pydantic_core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 42)) (2.33.2)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (2.9.0.post0)\n",
            "Collecting python-dotenv==1.1.1 (from -r requirements.txt (line 44))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 45)) (2025.2)\n",
            "Requirement already satisfied: PyYAML==6.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 46)) (6.0.3)\n",
            "Collecting qdrant-client==1.15.1 (from -r requirements.txt (line 47))\n",
            "  Downloading qdrant_client-1.15.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting regex==2025.9.18 (from -r requirements.txt (line 48))\n",
            "  Downloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.32.5 (from -r requirements.txt (line 49))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: safetensors==0.6.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 50)) (0.6.2)\n",
            "Collecting scikit-learn==1.7.2 (from -r requirements.txt (line 51))\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy==1.16.2 (from -r requirements.txt (line 52))\n",
            "  Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers==5.1.1 (from -r requirements.txt (line 53))\n",
            "  Downloading sentence_transformers-5.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting setuptools==80.9.0 (from -r requirements.txt (line 54))\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 55)) (1.17.0)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 56)) (1.3.1)\n",
            "Collecting starlette==0.48.0 (from -r requirements.txt (line 57))\n",
            "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting sympy==1.14.0 (from -r requirements.txt (line 58))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: threadpoolctl==3.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 59)) (3.6.0)\n",
            "Requirement already satisfied: tokenizers==0.22.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 60)) (0.22.1)\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 61)) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 62)) (4.67.1)\n",
            "Collecting transformers==4.57.0 (from -r requirements.txt (line 63))\n",
            "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-inspection==0.4.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 64)) (0.4.2)\n",
            "Requirement already satisfied: typing_extensions==4.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 65)) (4.15.0)\n",
            "Requirement already satisfied: tzdata==2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 66)) (2025.2)\n",
            "Requirement already satisfied: urllib3==2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 67)) (2.5.0)\n",
            "Collecting uvicorn==0.37.0 (from -r requirements.txt (line 68))\n",
            "  Downloading uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: xxhash==3.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 69)) (3.6.0)\n",
            "Collecting yarl==1.20.1 (from -r requirements.txt (line 70))\n",
            "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 61)) (3.4.0)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'transformers' candidate (version 4.57.0 at https://files.pythonhosted.org/packages/e5/2b/4d2708ac1ff5cd708b6548f4c5812d0ae40d1c28591c4c1c762b6dbdef2d/transformers-4.57.0-py3-none-any.whl (from https://pypi.org/simple/transformers/) (requires-python:>=3.9.0))\n",
            "Reason for being yanked: Error in the setup causing installation issues\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.118.0-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m139.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading qdrant_client-1.15.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.0/802.0 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m140.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-5.1.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.6/486.6 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m146.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m146.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.6/355.6 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, sympy, setuptools, regex, python-dotenv, pyarrow, protobuf, propcache, portalocker, numpy, multidict, idna, hf-xet, grpcio, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, yarl, scipy, requests, pandas, starlette, scikit-learn, huggingface-hub, aiohttp, fastapi, transformers, qdrant-client, datasets, sentence-transformers\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.38.0\n",
            "    Uninstalling uvicorn-0.38.0:\n",
            "      Successfully uninstalled uvicorn-0.38.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: python-dotenv\n",
            "    Found existing installation: python-dotenv 1.2.1\n",
            "    Uninstalling python-dotenv-1.2.1:\n",
            "      Successfully uninstalled python-dotenv-1.2.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.4.1\n",
            "    Uninstalling propcache-0.4.1:\n",
            "      Successfully uninstalled propcache-0.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.7.0\n",
            "    Uninstalling multidict-6.7.0:\n",
            "      Successfully uninstalled multidict-6.7.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.2.0\n",
            "    Uninstalling hf-xet-1.2.0:\n",
            "      Successfully uninstalled hf-xet-1.2.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.76.0\n",
            "    Uninstalling grpcio-1.76.0:\n",
            "      Successfully uninstalled grpcio-1.76.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.8.0\n",
            "    Uninstalling frozenlist-1.8.0:\n",
            "      Successfully uninstalled frozenlist-1.8.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.10.5\n",
            "    Uninstalling certifi-2025.10.5:\n",
            "      Successfully uninstalled certifi-2025.10.5\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.4.0\n",
            "    Uninstalling attrs-25.4.0:\n",
            "      Successfully uninstalled attrs-25.4.0\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.22.0\n",
            "    Uninstalling yarl-1.22.0:\n",
            "      Successfully uninstalled yarl-1.22.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.49.3\n",
            "    Uninstalling starlette-0.49.3:\n",
            "      Successfully uninstalled starlette-0.49.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.13.2\n",
            "    Uninstalling aiohttp-3.13.2:\n",
            "      Successfully uninstalled aiohttp-3.13.2\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.121.1\n",
            "    Uninstalling fastapi-0.121.1:\n",
            "      Successfully uninstalled fastapi-0.121.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.1\n",
            "    Uninstalling transformers-4.57.1:\n",
            "      Successfully uninstalled transformers-4.57.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 5.1.2\n",
            "    Uninstalling sentence-transformers-5.1.2:\n",
            "      Successfully uninstalled sentence-transformers-5.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.32.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.12.15 attrs-25.3.0 certifi-2025.8.3 charset-normalizer-3.4.3 datasets-4.1.1 dill-0.4.0 fastapi-0.118.0 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.9.0 grpcio-1.75.1 hf-xet-1.1.10 huggingface-hub-0.35.3 idna-3.10 multidict-6.6.4 numpy-2.3.3 pandas-2.3.3 portalocker-3.2.0 propcache-0.3.2 protobuf-6.32.1 pyarrow-21.0.0 python-dotenv-1.1.1 qdrant-client-1.15.1 regex-2025.9.18 requests-2.32.5 scikit-learn-1.7.2 scipy-1.16.2 sentence-transformers-5.1.1 setuptools-80.9.0 starlette-0.48.0 sympy-1.14.0 transformers-4.57.0 uvicorn-0.37.0 yarl-1.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "google",
                  "numpy"
                ]
              },
              "id": "b3a9d7ba8ffc465daa11f5f785402dbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!git clone -b ultimate https://github.com/mindPazi/ML-for-context.git\n",
        "%cd ML-for-context\n",
        "\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Boa_5B1zQJMz",
        "outputId": "585a5e54-6fd6-452b-8b9f-c745a8e2b2b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Files modified\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "config_path = \"src/training/config.py\"\n",
        "with open(config_path, \"r\") as f:\n",
        "    content = f.read()\n",
        "content = re.sub(\n",
        "    r'output_model_path: str = \".*?\"',\n",
        "    'output_model_path: str = \"/content/drive/MyDrive/ML-for-context/models/ultimate\"',\n",
        "    content\n",
        ")\n",
        "with open(config_path, \"w\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "evaluate_path = \"src/evaluation/evaluate.py\"\n",
        "with open(evaluate_path, \"r\") as f:\n",
        "    content = f.read()\n",
        "content = re.sub(\n",
        "    r'cache_dir = \"\\./cache/embeddings\"',\n",
        "    'cache_dir = \"/content/drive/MyDrive/ML-for-context/cache-ultimate/embeddings\"',\n",
        "    content\n",
        ")\n",
        "with open(evaluate_path, \"w\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"✓ Files modified\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLHA8X6LRhj6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ik-dFhXQwjE",
        "outputId": "9cbe0c15-45b5-4f47-a55d-7a215cc1ed72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Fixed score_function to main_score_function\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "train_path = \"src/training/train.py\"\n",
        "with open(train_path, \"r\") as f:\n",
        "    content = f.read()\n",
        "\n",
        "content = re.sub(\n",
        "    r'from sentence_transformers import SentenceTransformer, losses, evaluation\\nfrom sentence_transformers.evaluation import SimilarityFunction',\n",
        "    'from sentence_transformers import SentenceTransformer, losses, evaluation, SimilarityFunction',\n",
        "    content\n",
        ")\n",
        "\n",
        "content = re.sub(\n",
        "    r'score_function=SimilarityFunction\\.MANHATTAN,',\n",
        "    'main_score_function=SimilarityFunction.MANHATTAN,',\n",
        "    content\n",
        ")\n",
        "\n",
        "with open(train_path, \"w\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"✓ Fixed score_function to main_score_function\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaH20aImRY22"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZnepKXURt3y",
        "outputId": "45a0d98b-6d6b-4f1c-f710-f36d6265d688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-20 03:45:43.762282: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763610343.782172    7516 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763610343.788196    7516 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763610343.803182    7516 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763610343.803208    7516 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763610343.803212    7516 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763610343.803215    7516 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-20 03:45:43.807691: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\n",
            "============================================================\n",
            "         FINE-TUNING EMBEDDING MODEL ON COSQA\n",
            "============================================================\n",
            "\n",
            "[Configuration]\n",
            "  Base Model:        microsoft/unixcoder-base\n",
            "  Output Path:       /content/drive/MyDrive/ML-for-context/models/ultimate\n",
            "  Device:            cuda\n",
            "  Batch Size:        32\n",
            "  Epochs:            20\n",
            "  Learning Rate:     1e-05\n",
            "  Max Seq Length:    256\n",
            "  Early Stop Patience: 3\n",
            "\n",
            "[Data Preparation]\n",
            "==================================================\n",
            "[1/3] Loading CoSQA dataset...\n",
            "      Corpus size: 20604\n",
            "      Total queries: 19604\n",
            "      Query deduplication: 19604 → 19604 queries (0 removed)\n",
            "      Document deduplication: 20604 → 6267 documents (14337 removed)\n",
            "\n",
            "[2/3] Splitting queries into train/validation (80/20)...\n",
            "      Train queries: 15683 (80%)\n",
            "      Val queries: 3921 (20%)\n",
            "      (Test queries: 500 from CoSQA test split)\n",
            "\n",
            "[3/3] Creating query-document pairs for training...\n",
            "      Train pairs: 15683\n",
            "==================================================\n",
            "\n",
            "[Model Initialization]\n",
            "Loading base model: microsoft/unixcoder-base...\n",
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name microsoft/unixcoder-base. Creating a new one with mean pooling.\n",
            "  Embedding dim: 768\n",
            "  Max seq length: 256\n",
            "\n",
            "[DataLoader Setup]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "  Train batches: 491\n",
            "  Batch size: 32\n",
            "  Workers: 4\n",
            "\n",
            "[Loss Function]\n",
            "  Using: MultipleNegativesRankingLoss\n",
            "\n",
            "[Validation Setup]\n",
            "  Validation queries: 3921\n",
            "  Validation corpus: 6267\n",
            "\n",
            "[Training]\n",
            "============================================================\n",
            "Total training steps: 9820\n",
            "Warmup steps: 982\n",
            "Starting training at: 2025-11-20 03:45:57\n",
            "------------------------------------------------------------\n",
            "\n",
            "Epoch 1/20\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "{'train_runtime': 161.5914, 'train_samples_per_second': 97.053, 'train_steps_per_second': 3.039, 'train_loss': 0.5958549670435018, 'epoch': 1.0}\n",
            "100% 491/491 [02:41<00:00,  3.04it/s]\n",
            "\n",
            "  Validating...\n",
            "Batches: 100% 123/123 [00:01<00:00, 79.75it/s]\n",
            "Corpus Chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Batches:   0% 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Batches:   1% 2/196 [00:00<00:13, 14.01it/s]\u001b[A\n",
            "Batches:   2% 4/196 [00:00<00:17, 10.88it/s]\u001b[A\n",
            "Batches:   3% 6/196 [00:00<00:18, 10.32it/s]\u001b[A\n",
            "Batches:   4% 8/196 [00:00<00:18, 10.38it/s]\u001b[A\n",
            "Batches:   5% 10/196 [00:00<00:18,  9.89it/s]\u001b[A\n",
            "Batches:   6% 12/196 [00:01<00:17, 10.30it/s]\u001b[A\n",
            "Batches:   7% 14/196 [00:01<00:16, 11.03it/s]\u001b[A\n",
            "Batches:   8% 16/196 [00:01<00:15, 11.26it/s]\u001b[A\n",
            "Batches:   9% 18/196 [00:01<00:14, 12.07it/s]\u001b[A\n",
            "Batches:  10% 20/196 [00:01<00:13, 12.69it/s]\u001b[A\n",
            "Batches:  11% 22/196 [00:01<00:13, 12.62it/s]\u001b[A\n",
            "Batches:  12% 24/196 [00:02<00:13, 12.70it/s]\u001b[A\n",
            "Batches:  13% 26/196 [00:02<00:12, 13.16it/s]\u001b[A\n",
            "Batches:  14% 28/196 [00:02<00:12, 13.81it/s]\u001b[A\n",
            "Batches:  15% 30/196 [00:02<00:11, 14.49it/s]\u001b[A\n",
            "Batches:  16% 32/196 [00:02<00:11, 14.80it/s]\u001b[A\n",
            "Batches:  17% 34/196 [00:02<00:11, 14.71it/s]\u001b[A\n",
            "Batches:  18% 36/196 [00:02<00:10, 14.94it/s]\u001b[A\n",
            "Batches:  19% 38/196 [00:02<00:10, 14.79it/s]\u001b[A\n",
            "Batches:  20% 40/196 [00:03<00:10, 15.05it/s]\u001b[A\n",
            "Batches:  21% 42/196 [00:03<00:09, 15.42it/s]\u001b[A\n",
            "Batches:  22% 44/196 [00:03<00:09, 15.76it/s]\u001b[A\n",
            "Batches:  23% 46/196 [00:03<00:09, 15.87it/s]\u001b[A\n",
            "Batches:  24% 48/196 [00:03<00:08, 16.88it/s]\u001b[A\n",
            "Batches:  26% 50/196 [00:03<00:08, 17.32it/s]\u001b[A\n",
            "Batches:  27% 52/196 [00:03<00:08, 17.21it/s]\u001b[A\n",
            "Batches:  28% 54/196 [00:03<00:08, 16.81it/s]\u001b[A\n",
            "Batches:  29% 56/196 [00:04<00:08, 16.96it/s]\u001b[A\n",
            "Batches:  30% 58/196 [00:04<00:08, 17.04it/s]\u001b[A\n",
            "Batches:  31% 60/196 [00:04<00:07, 17.75it/s]\u001b[A\n",
            "Batches:  32% 63/196 [00:04<00:07, 17.88it/s]\u001b[A\n",
            "Batches:  34% 66/196 [00:04<00:06, 19.06it/s]\u001b[A\n",
            "Batches:  35% 69/196 [00:04<00:06, 19.78it/s]\u001b[A\n",
            "Batches:  37% 72/196 [00:04<00:06, 20.15it/s]\u001b[A\n",
            "Batches:  38% 75/196 [00:05<00:05, 20.39it/s]\u001b[A\n",
            "Batches:  40% 78/196 [00:05<00:05, 20.61it/s]\u001b[A\n",
            "Batches:  41% 81/196 [00:05<00:05, 20.81it/s]\u001b[A\n",
            "Batches:  43% 84/196 [00:05<00:05, 21.43it/s]\u001b[A\n",
            "Batches:  44% 87/196 [00:05<00:04, 21.98it/s]\u001b[A\n",
            "Batches:  46% 90/196 [00:05<00:04, 21.82it/s]\u001b[A\n",
            "Batches:  47% 93/196 [00:05<00:04, 21.99it/s]\u001b[A\n",
            "Batches:  49% 96/196 [00:05<00:04, 22.74it/s]\u001b[A\n",
            "Batches:  51% 99/196 [00:06<00:04, 22.90it/s]\u001b[A\n",
            "Batches:  52% 102/196 [00:06<00:04, 22.81it/s]\u001b[A\n",
            "Batches:  54% 105/196 [00:06<00:03, 23.98it/s]\u001b[A\n",
            "Batches:  55% 108/196 [00:06<00:03, 24.62it/s]\u001b[A\n",
            "Batches:  57% 111/196 [00:06<00:03, 25.28it/s]\u001b[A\n",
            "Batches:  58% 114/196 [00:06<00:03, 25.69it/s]\u001b[A\n",
            "Batches:  60% 117/196 [00:06<00:03, 25.49it/s]\u001b[A\n",
            "Batches:  61% 120/196 [00:06<00:02, 25.35it/s]\u001b[A\n",
            "Batches:  63% 123/196 [00:07<00:02, 25.76it/s]\u001b[A\n",
            "Batches:  65% 127/196 [00:07<00:02, 27.05it/s]\u001b[A\n",
            "Batches:  66% 130/196 [00:07<00:02, 26.84it/s]\u001b[A\n",
            "Batches:  68% 134/196 [00:07<00:02, 28.10it/s]\u001b[A\n",
            "Batches:  70% 138/196 [00:07<00:01, 29.07it/s]\u001b[A\n",
            "Batches:  72% 142/196 [00:07<00:01, 29.80it/s]\u001b[A\n",
            "Batches:  74% 146/196 [00:07<00:01, 30.20it/s]\u001b[A\n",
            "Batches:  77% 150/196 [00:07<00:01, 30.00it/s]\u001b[A\n",
            "Batches:  79% 154/196 [00:08<00:01, 31.00it/s]\u001b[A\n",
            "Batches:  81% 158/196 [00:08<00:01, 31.16it/s]\u001b[A\n",
            "Batches:  83% 162/196 [00:08<00:01, 31.68it/s]\u001b[A\n",
            "Batches:  85% 166/196 [00:08<00:00, 32.09it/s]\u001b[A\n",
            "Batches:  87% 170/196 [00:08<00:00, 32.59it/s]\u001b[A\n",
            "Batches:  89% 174/196 [00:08<00:00, 32.38it/s]\u001b[A\n",
            "Batches:  91% 178/196 [00:08<00:00, 34.00it/s]\u001b[A\n",
            "Batches:  93% 182/196 [00:08<00:00, 35.02it/s]\u001b[A\n",
            "Batches:  95% 186/196 [00:08<00:00, 34.21it/s]\u001b[A\n",
            "Batches:  97% 191/196 [00:09<00:00, 36.53it/s]\u001b[A\n",
            "Batches: 100% 196/196 [00:09<00:00, 21.28it/s]\n",
            "Corpus Chunks: 100% 1/1 [00:09<00:00,  9.64s/it]\n",
            "  Validation NDCG@10: 0.4724\n",
            "  Validation RECALL@10: 0.6838\n",
            "  Validation MRR@10: 0.4061\n",
            "  Saving best model (score: 0.4724)...\n",
            "\n",
            "Epoch 2/20\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "{'train_runtime': 170.2243, 'train_samples_per_second': 92.131, 'train_steps_per_second': 2.884, 'train_loss': 0.3322740543155709, 'epoch': 1.0}\n",
            "100% 491/491 [02:50<00:00,  2.88it/s]\n",
            "\n",
            "  Validating...\n",
            "Batches: 100% 123/123 [00:01<00:00, 80.52it/s]\n",
            "Corpus Chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Batches:   0% 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Batches:   1% 2/196 [00:00<00:16, 12.01it/s]\u001b[A\n",
            "Batches:   2% 4/196 [00:00<00:18, 10.20it/s]\u001b[A\n",
            "Batches:   3% 6/196 [00:00<00:19,  9.84it/s]\u001b[A\n",
            "Batches:   4% 8/196 [00:00<00:18, 10.02it/s]\u001b[A\n",
            "Batches:   5% 10/196 [00:01<00:19,  9.59it/s]\u001b[A\n",
            "Batches:   6% 12/196 [00:01<00:18, 10.13it/s]\u001b[A\n",
            "Batches:   7% 14/196 [00:01<00:16, 10.84it/s]\u001b[A\n",
            "Batches:   8% 16/196 [00:01<00:16, 11.11it/s]\u001b[A\n",
            "Batches:   9% 18/196 [00:01<00:14, 11.95it/s]\u001b[A\n",
            "Batches:  10% 20/196 [00:01<00:14, 12.54it/s]\u001b[A\n",
            "Batches:  11% 22/196 [00:01<00:14, 12.35it/s]\u001b[A\n",
            "Batches:  12% 24/196 [00:02<00:13, 12.38it/s]\u001b[A\n",
            "Batches:  13% 26/196 [00:02<00:13, 12.95it/s]\u001b[A\n",
            "Batches:  14% 28/196 [00:02<00:12, 13.66it/s]\u001b[A\n",
            "Batches:  15% 30/196 [00:02<00:11, 14.42it/s]\u001b[A\n",
            "Batches:  16% 32/196 [00:02<00:11, 14.77it/s]\u001b[A\n",
            "Batches:  17% 34/196 [00:02<00:11, 14.64it/s]\u001b[A\n",
            "Batches:  18% 36/196 [00:02<00:10, 14.85it/s]\u001b[A\n",
            "Batches:  19% 38/196 [00:03<00:10, 14.73it/s]\u001b[A\n",
            "Batches:  20% 40/196 [00:03<00:10, 14.96it/s]\u001b[A\n",
            "Batches:  21% 42/196 [00:03<00:10, 15.35it/s]\u001b[A\n",
            "Batches:  22% 44/196 [00:03<00:09, 15.51it/s]\u001b[A\n",
            "Batches:  23% 46/196 [00:03<00:09, 15.62it/s]\u001b[A\n",
            "Batches:  24% 48/196 [00:03<00:08, 16.52it/s]\u001b[A\n",
            "Batches:  26% 50/196 [00:03<00:08, 16.96it/s]\u001b[A\n",
            "Batches:  27% 52/196 [00:03<00:08, 16.86it/s]\u001b[A\n",
            "Batches:  28% 54/196 [00:04<00:08, 16.59it/s]\u001b[A\n",
            "Batches:  29% 56/196 [00:04<00:08, 16.95it/s]\u001b[A\n",
            "Batches:  30% 58/196 [00:04<00:08, 17.08it/s]\u001b[A\n",
            "Batches:  31% 60/196 [00:04<00:07, 17.67it/s]\u001b[A\n",
            "Batches:  32% 63/196 [00:04<00:07, 18.17it/s]\u001b[A\n",
            "Batches:  33% 65/196 [00:04<00:07, 18.53it/s]\u001b[A\n",
            "Batches:  35% 68/196 [00:04<00:06, 19.29it/s]\u001b[A\n",
            "Batches:  36% 71/196 [00:04<00:06, 19.72it/s]\u001b[A\n",
            "Batches:  38% 74/196 [00:05<00:06, 19.96it/s]\u001b[A\n",
            "Batches:  39% 77/196 [00:05<00:05, 20.37it/s]\u001b[A\n",
            "Batches:  41% 80/196 [00:05<00:05, 20.45it/s]\u001b[A\n",
            "Batches:  42% 83/196 [00:05<00:05, 21.23it/s]\u001b[A\n",
            "Batches:  44% 86/196 [00:05<00:04, 22.03it/s]\u001b[A\n",
            "Batches:  45% 89/196 [00:05<00:04, 21.46it/s]\u001b[A\n",
            "Batches:  47% 92/196 [00:05<00:04, 21.73it/s]\u001b[A\n",
            "Batches:  48% 95/196 [00:05<00:04, 22.54it/s]\u001b[A\n",
            "Batches:  50% 98/196 [00:06<00:04, 22.43it/s]\u001b[A\n",
            "Batches:  52% 101/196 [00:06<00:04, 22.28it/s]\u001b[A\n",
            "Batches:  53% 104/196 [00:06<00:03, 23.68it/s]\u001b[A\n",
            "Batches:  55% 107/196 [00:06<00:03, 24.46it/s]\u001b[A\n",
            "Batches:  56% 110/196 [00:06<00:03, 25.24it/s]\u001b[A\n",
            "Batches:  58% 113/196 [00:06<00:03, 24.92it/s]\u001b[A\n",
            "Batches:  59% 116/196 [00:06<00:03, 24.86it/s]\u001b[A\n",
            "Batches:  61% 119/196 [00:06<00:03, 25.15it/s]\u001b[A\n",
            "Batches:  62% 122/196 [00:07<00:02, 25.53it/s]\u001b[A\n",
            "Batches:  64% 125/196 [00:07<00:02, 25.53it/s]\u001b[A\n",
            "Batches:  65% 128/196 [00:07<00:02, 26.18it/s]\u001b[A\n",
            "Batches:  67% 132/196 [00:07<00:02, 27.41it/s]\u001b[A\n",
            "Batches:  69% 136/196 [00:07<00:02, 28.92it/s]\u001b[A\n",
            "Batches:  71% 139/196 [00:07<00:01, 28.96it/s]\u001b[A\n",
            "Batches:  72% 142/196 [00:07<00:01, 28.87it/s]\u001b[A\n",
            "Batches:  74% 146/196 [00:07<00:01, 28.98it/s]\u001b[A\n",
            "Batches:  77% 150/196 [00:08<00:01, 29.61it/s]\u001b[A\n",
            "Batches:  79% 154/196 [00:08<00:01, 30.26it/s]\u001b[A\n",
            "Batches:  81% 158/196 [00:08<00:01, 30.77it/s]\u001b[A\n",
            "Batches:  83% 162/196 [00:08<00:01, 30.67it/s]\u001b[A\n",
            "Batches:  85% 166/196 [00:08<00:00, 31.47it/s]\u001b[A\n",
            "Batches:  87% 170/196 [00:08<00:00, 32.21it/s]\u001b[A\n",
            "Batches:  89% 174/196 [00:08<00:00, 32.64it/s]\u001b[A\n",
            "Batches:  91% 178/196 [00:08<00:00, 33.86it/s]\u001b[A\n",
            "Batches:  93% 182/196 [00:08<00:00, 34.71it/s]\u001b[A\n",
            "Batches:  95% 186/196 [00:09<00:00, 34.41it/s]\u001b[A\n",
            "Batches:  97% 190/196 [00:09<00:00, 34.90it/s]\u001b[A\n",
            "Batches: 100% 196/196 [00:09<00:00, 20.94it/s]\n",
            "Corpus Chunks: 100% 1/1 [00:09<00:00,  9.80s/it]\n",
            "  Validation NDCG@10: 0.5041\n",
            "  Validation RECALL@10: 0.7228\n",
            "  Validation MRR@10: 0.4352\n",
            "  Saving best model (score: 0.5041)...\n",
            "      ✓ New best score: 0.5041\n",
            "\n",
            "Epoch 3/20\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "{'train_runtime': 169.8723, 'train_samples_per_second': 92.322, 'train_steps_per_second': 2.89, 'train_loss': 0.19967286212866758, 'epoch': 1.0}\n",
            "100% 491/491 [02:49<00:00,  2.89it/s]\n",
            "\n",
            "  Validating...\n",
            "Batches: 100% 123/123 [00:01<00:00, 82.60it/s]\n",
            "Corpus Chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Batches:   0% 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Batches:   1% 2/196 [00:00<00:13, 13.86it/s]\u001b[A\n",
            "Batches:   2% 4/196 [00:00<00:18, 10.66it/s]\u001b[A\n",
            "Batches:   3% 6/196 [00:00<00:18, 10.09it/s]\u001b[A\n",
            "Batches:   4% 8/196 [00:00<00:18, 10.16it/s]\u001b[A\n",
            "Batches:   5% 10/196 [00:00<00:19,  9.72it/s]\u001b[A\n",
            "Batches:   6% 12/196 [00:01<00:18, 10.22it/s]\u001b[A\n",
            "Batches:   7% 14/196 [00:01<00:16, 10.91it/s]\u001b[A\n",
            "Batches:   8% 16/196 [00:01<00:16, 11.16it/s]\u001b[A\n",
            "Batches:   9% 18/196 [00:01<00:14, 11.97it/s]\u001b[A\n",
            "Batches:  10% 20/196 [00:01<00:13, 12.58it/s]\u001b[A\n",
            "Batches:  11% 22/196 [00:01<00:14, 12.38it/s]\u001b[A\n",
            "Batches:  12% 24/196 [00:02<00:13, 12.54it/s]\u001b[A\n",
            "Batches:  13% 26/196 [00:02<00:13, 12.82it/s]\u001b[A\n",
            "Batches:  14% 28/196 [00:02<00:12, 13.70it/s]\u001b[A\n",
            "Batches:  15% 30/196 [00:02<00:11, 14.35it/s]\u001b[A\n",
            "Batches:  16% 32/196 [00:02<00:11, 14.70it/s]\u001b[A\n",
            "Batches:  17% 34/196 [00:02<00:11, 14.34it/s]\u001b[A\n",
            "Batches:  18% 36/196 [00:02<00:10, 14.70it/s]\u001b[A\n",
            "Batches:  19% 38/196 [00:03<00:10, 14.56it/s]\u001b[A\n",
            "Batches:  20% 40/196 [00:03<00:10, 14.88it/s]\u001b[A\n",
            "Batches:  21% 42/196 [00:03<00:10, 15.00it/s]\u001b[A\n",
            "Batches:  22% 44/196 [00:03<00:09, 15.66it/s]\u001b[A\n",
            "Batches:  23% 46/196 [00:03<00:09, 15.59it/s]\u001b[A\n",
            "Batches:  24% 48/196 [00:03<00:08, 16.62it/s]\u001b[A\n",
            "Batches:  26% 50/196 [00:03<00:08, 16.87it/s]\u001b[A\n",
            "Batches:  27% 52/196 [00:03<00:08, 16.63it/s]\u001b[A\n",
            "Batches:  28% 54/196 [00:04<00:08, 16.47it/s]\u001b[A\n",
            "Batches:  29% 56/196 [00:04<00:08, 16.70it/s]\u001b[A\n",
            "Batches:  30% 58/196 [00:04<00:08, 16.96it/s]\u001b[A\n",
            "Batches:  31% 60/196 [00:04<00:07, 17.56it/s]\u001b[A\n",
            "Batches:  32% 62/196 [00:04<00:07, 18.21it/s]\u001b[A\n",
            "Batches:  33% 64/196 [00:04<00:07, 18.25it/s]\u001b[A\n",
            "Batches:  34% 66/196 [00:04<00:06, 18.63it/s]\u001b[A\n",
            "Batches:  35% 69/196 [00:04<00:06, 19.43it/s]\u001b[A\n",
            "Batches:  37% 72/196 [00:04<00:06, 19.77it/s]\u001b[A\n",
            "Batches:  38% 75/196 [00:05<00:05, 20.19it/s]\u001b[A\n",
            "Batches:  40% 78/196 [00:05<00:05, 20.32it/s]\u001b[A\n",
            "Batches:  41% 81/196 [00:05<00:05, 20.65it/s]\u001b[A\n",
            "Batches:  43% 84/196 [00:05<00:05, 21.29it/s]\u001b[A\n",
            "Batches:  44% 87/196 [00:05<00:05, 21.69it/s]\u001b[A\n",
            "Batches:  46% 90/196 [00:05<00:04, 21.59it/s]\u001b[A\n",
            "Batches:  47% 93/196 [00:05<00:04, 21.46it/s]\u001b[A\n",
            "Batches:  49% 96/196 [00:06<00:04, 22.06it/s]\u001b[A\n",
            "Batches:  51% 99/196 [00:06<00:04, 22.57it/s]\u001b[A\n",
            "Batches:  52% 102/196 [00:06<00:04, 22.88it/s]\u001b[A\n",
            "Batches:  54% 105/196 [00:06<00:03, 23.92it/s]\u001b[A\n",
            "Batches:  55% 108/196 [00:06<00:03, 24.64it/s]\u001b[A\n",
            "Batches:  57% 111/196 [00:06<00:03, 25.06it/s]\u001b[A\n",
            "Batches:  58% 114/196 [00:06<00:03, 25.02it/s]\u001b[A\n",
            "Batches:  60% 117/196 [00:06<00:03, 25.01it/s]\u001b[A\n",
            "Batches:  61% 120/196 [00:06<00:02, 25.34it/s]\u001b[A\n",
            "Batches:  63% 123/196 [00:07<00:02, 25.60it/s]\u001b[A\n",
            "Batches:  64% 126/196 [00:07<00:02, 26.28it/s]\u001b[A\n",
            "Batches:  66% 129/196 [00:07<00:02, 26.57it/s]\u001b[A\n",
            "Batches:  67% 132/196 [00:07<00:02, 26.98it/s]\u001b[A\n",
            "Batches:  69% 136/196 [00:07<00:02, 28.54it/s]\u001b[A\n",
            "Batches:  71% 139/196 [00:07<00:01, 28.76it/s]\u001b[A\n",
            "Batches:  72% 142/196 [00:07<00:01, 29.07it/s]\u001b[A\n",
            "Batches:  74% 145/196 [00:07<00:01, 29.10it/s]\u001b[A\n",
            "Batches:  76% 149/196 [00:07<00:01, 29.53it/s]\u001b[A\n",
            "Batches:  78% 152/196 [00:08<00:01, 29.65it/s]\u001b[A\n",
            "Batches:  79% 155/196 [00:08<00:01, 29.18it/s]\u001b[A\n",
            "Batches:  81% 159/196 [00:08<00:01, 30.57it/s]\u001b[A\n",
            "Batches:  83% 163/196 [00:08<00:01, 30.49it/s]\u001b[A\n",
            "Batches:  85% 167/196 [00:08<00:00, 31.52it/s]\u001b[A\n",
            "Batches:  87% 171/196 [00:08<00:00, 31.78it/s]\u001b[A\n",
            "Batches:  89% 175/196 [00:08<00:00, 32.20it/s]\u001b[A\n",
            "Batches:  91% 179/196 [00:08<00:00, 33.85it/s]\u001b[A\n",
            "Batches:  93% 183/196 [00:09<00:00, 34.00it/s]\u001b[A\n",
            "Batches:  95% 187/196 [00:09<00:00, 35.29it/s]\u001b[A\n",
            "Batches:  97% 191/196 [00:09<00:00, 32.81it/s]\u001b[A\n",
            "Batches: 100% 196/196 [00:09<00:00, 20.79it/s]\n",
            "Corpus Chunks: 100% 1/1 [00:09<00:00,  9.86s/it]\n",
            "  Validation NDCG@10: 0.5147\n",
            "  Validation RECALL@10: 0.7358\n",
            "  Validation MRR@10: 0.4453\n",
            "  Saving best model (score: 0.5147)...\n",
            "      ✓ New best score: 0.5147\n",
            "\n",
            "Epoch 4/20\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "{'train_runtime': 169.8564, 'train_samples_per_second': 92.331, 'train_steps_per_second': 2.891, 'train_loss': 0.1218459290545244, 'epoch': 1.0}\n",
            "100% 491/491 [02:49<00:00,  2.89it/s]\n",
            "\n",
            "  Validating...\n",
            "Batches: 100% 123/123 [00:01<00:00, 62.13it/s]\n",
            "Corpus Chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Batches:   0% 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Batches:   1% 2/196 [00:00<00:14, 13.52it/s]\u001b[A\n",
            "Batches:   2% 4/196 [00:00<00:18, 10.56it/s]\u001b[A\n",
            "Batches:   3% 6/196 [00:00<00:18, 10.12it/s]\u001b[A\n",
            "Batches:   4% 8/196 [00:00<00:18, 10.24it/s]\u001b[A\n",
            "Batches:   5% 10/196 [00:00<00:19,  9.63it/s]\u001b[A\n",
            "Batches:   6% 12/196 [00:01<00:18, 10.11it/s]\u001b[A\n",
            "Batches:   7% 14/196 [00:01<00:16, 10.78it/s]\u001b[A\n",
            "Batches:   8% 16/196 [00:01<00:16, 11.18it/s]\u001b[A\n",
            "Batches:   9% 18/196 [00:01<00:14, 11.99it/s]\u001b[A\n",
            "Batches:  10% 20/196 [00:01<00:13, 12.58it/s]\u001b[A\n",
            "Batches:  11% 22/196 [00:01<00:14, 12.35it/s]\u001b[A\n",
            "Batches:  12% 24/196 [00:02<00:13, 12.48it/s]\u001b[A\n",
            "Batches:  13% 26/196 [00:02<00:13, 12.96it/s]\u001b[A\n",
            "Batches:  14% 28/196 [00:02<00:12, 13.57it/s]\u001b[A\n",
            "Batches:  15% 30/196 [00:02<00:11, 14.32it/s]\u001b[A\n",
            "Batches:  16% 32/196 [00:02<00:11, 14.69it/s]\u001b[A\n",
            "Batches:  17% 34/196 [00:02<00:11, 14.52it/s]\u001b[A\n",
            "Batches:  18% 36/196 [00:02<00:10, 14.71it/s]\u001b[A\n",
            "Batches:  19% 38/196 [00:03<00:10, 14.58it/s]\u001b[A\n",
            "Batches:  20% 40/196 [00:03<00:10, 14.79it/s]\u001b[A\n",
            "Batches:  21% 42/196 [00:03<00:10, 15.22it/s]\u001b[A\n",
            "Batches:  22% 44/196 [00:03<00:09, 15.56it/s]\u001b[A\n",
            "Batches:  23% 46/196 [00:03<00:09, 15.65it/s]\u001b[A\n",
            "Batches:  24% 48/196 [00:03<00:09, 16.44it/s]\u001b[A\n",
            "Batches:  26% 50/196 [00:03<00:08, 16.98it/s]\u001b[A\n",
            "Batches:  27% 52/196 [00:03<00:08, 16.71it/s]\u001b[A\n",
            "Batches:  28% 54/196 [00:04<00:08, 16.60it/s]\u001b[A\n",
            "Batches:  29% 56/196 [00:04<00:08, 16.76it/s]\u001b[A\n",
            "Batches:  30% 58/196 [00:04<00:08, 16.94it/s]\u001b[A\n",
            "Batches:  31% 60/196 [00:04<00:07, 17.63it/s]\u001b[A\n",
            "Batches:  32% 62/196 [00:04<00:07, 18.24it/s]\u001b[A\n",
            "Batches:  33% 64/196 [00:04<00:07, 18.35it/s]\u001b[A\n",
            "Batches:  34% 66/196 [00:04<00:07, 18.54it/s]\u001b[A\n",
            "Batches:  35% 69/196 [00:04<00:06, 19.42it/s]\u001b[A\n",
            "Batches:  37% 72/196 [00:04<00:06, 19.85it/s]\u001b[A\n",
            "Batches:  38% 75/196 [00:05<00:06, 20.05it/s]\u001b[A\n",
            "Batches:  40% 78/196 [00:05<00:05, 20.44it/s]\u001b[A\n",
            "Batches:  41% 81/196 [00:05<00:05, 20.82it/s]\u001b[A\n",
            "Batches:  43% 84/196 [00:05<00:05, 21.39it/s]\u001b[A\n",
            "Batches:  44% 87/196 [00:05<00:04, 21.97it/s]\u001b[A\n",
            "Batches:  46% 90/196 [00:05<00:04, 21.79it/s]\u001b[A\n",
            "Batches:  47% 93/196 [00:05<00:04, 21.63it/s]\u001b[A\n",
            "Batches:  49% 96/196 [00:06<00:04, 22.29it/s]\u001b[A\n",
            "Batches:  51% 99/196 [00:06<00:04, 22.62it/s]\u001b[A\n",
            "Batches:  52% 102/196 [00:06<00:04, 22.94it/s]\u001b[A\n",
            "Batches:  54% 105/196 [00:06<00:03, 24.04it/s]\u001b[A\n",
            "Batches:  55% 108/196 [00:06<00:03, 24.55it/s]\u001b[A\n",
            "Batches:  57% 111/196 [00:06<00:03, 25.20it/s]\u001b[A\n",
            "Batches:  58% 114/196 [00:06<00:03, 24.88it/s]\u001b[A\n",
            "Batches:  60% 117/196 [00:06<00:03, 25.28it/s]\u001b[A\n",
            "Batches:  61% 120/196 [00:06<00:02, 25.64it/s]\u001b[A\n",
            "Batches:  63% 123/196 [00:07<00:02, 25.67it/s]\u001b[A\n",
            "Batches:  64% 126/196 [00:07<00:02, 26.08it/s]\u001b[A\n",
            "Batches:  66% 129/196 [00:07<00:02, 26.61it/s]\u001b[A\n",
            "Batches:  67% 132/196 [00:07<00:02, 27.25it/s]\u001b[A\n",
            "Batches:  69% 136/196 [00:07<00:02, 28.56it/s]\u001b[A\n",
            "Batches:  71% 139/196 [00:07<00:01, 28.64it/s]\u001b[A\n",
            "Batches:  72% 142/196 [00:07<00:01, 28.71it/s]\u001b[A\n",
            "Batches:  74% 146/196 [00:07<00:01, 29.15it/s]\u001b[A\n",
            "Batches:  77% 150/196 [00:08<00:01, 29.34it/s]\u001b[A\n",
            "Batches:  79% 154/196 [00:08<00:01, 30.13it/s]\u001b[A\n",
            "Batches:  81% 158/196 [00:08<00:01, 30.57it/s]\u001b[A\n",
            "Batches:  83% 162/196 [00:08<00:01, 30.53it/s]\u001b[A\n",
            "Batches:  85% 166/196 [00:08<00:00, 31.67it/s]\u001b[A\n",
            "Batches:  87% 170/196 [00:08<00:00, 32.21it/s]\u001b[A\n",
            "Batches:  89% 174/196 [00:08<00:00, 32.69it/s]\u001b[A\n",
            "Batches:  91% 178/196 [00:08<00:00, 33.87it/s]\u001b[A\n",
            "Batches:  93% 182/196 [00:08<00:00, 34.63it/s]\u001b[A\n",
            "Batches:  95% 186/196 [00:09<00:00, 35.28it/s]\u001b[A\n",
            "Batches:  97% 190/196 [00:09<00:00, 36.22it/s]\u001b[A\n",
            "Batches: 100% 196/196 [00:09<00:00, 20.97it/s]\n",
            "Corpus Chunks: 100% 1/1 [00:09<00:00,  9.77s/it]\n",
            "  Validation NDCG@10: 0.5198\n",
            "  Validation RECALL@10: 0.7467\n",
            "  Validation MRR@10: 0.4487\n",
            "  Saving best model (score: 0.5198)...\n",
            "      ✓ New best score: 0.5198\n",
            "\n",
            "Epoch 5/20\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "{'train_runtime': 169.715, 'train_samples_per_second': 92.408, 'train_steps_per_second': 2.893, 'train_loss': 0.08025788969517725, 'epoch': 1.0}\n",
            "100% 491/491 [02:49<00:00,  2.89it/s]\n",
            "\n",
            "  Validating...\n",
            "Batches: 100% 123/123 [00:02<00:00, 52.89it/s]\n",
            "Corpus Chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Batches:   0% 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Batches:   1% 2/196 [00:00<00:14, 13.58it/s]\u001b[A\n",
            "Batches:   2% 4/196 [00:00<00:17, 10.69it/s]\u001b[A\n",
            "Batches:   3% 6/196 [00:00<00:18, 10.18it/s]\u001b[A\n",
            "Batches:   4% 8/196 [00:00<00:18, 10.26it/s]\u001b[A\n",
            "Batches:   5% 10/196 [00:00<00:19,  9.78it/s]\u001b[A\n",
            "Batches:   6% 12/196 [00:01<00:18, 10.19it/s]\u001b[A\n",
            "Batches:   7% 14/196 [00:01<00:16, 10.93it/s]\u001b[A\n",
            "Batches:   8% 16/196 [00:01<00:16, 11.11it/s]\u001b[A\n",
            "Batches:   9% 18/196 [00:01<00:14, 11.90it/s]\u001b[A\n",
            "Batches:  10% 20/196 [00:01<00:13, 12.58it/s]\u001b[A\n",
            "Batches:  11% 22/196 [00:01<00:14, 12.36it/s]\u001b[A\n",
            "Batches:  12% 24/196 [00:02<00:13, 12.56it/s]\u001b[A\n",
            "Batches:  13% 26/196 [00:02<00:13, 12.93it/s]\u001b[A\n",
            "Batches:  14% 28/196 [00:02<00:12, 13.68it/s]\u001b[A\n",
            "Batches:  15% 30/196 [00:02<00:11, 14.36it/s]\u001b[A\n",
            "Batches:  16% 32/196 [00:02<00:11, 14.68it/s]\u001b[A\n",
            "Batches:  17% 34/196 [00:02<00:11, 14.57it/s]\u001b[A\n",
            "Batches:  18% 36/196 [00:02<00:10, 14.66it/s]\u001b[A\n",
            "Batches:  19% 38/196 [00:03<00:10, 14.70it/s]\u001b[A\n",
            "Batches:  20% 40/196 [00:03<00:10, 14.97it/s]\u001b[A\n",
            "Batches:  21% 42/196 [00:03<00:10, 15.35it/s]\u001b[A\n",
            "Batches:  22% 44/196 [00:03<00:09, 15.58it/s]\u001b[A\n",
            "Batches:  23% 46/196 [00:03<00:09, 15.60it/s]\u001b[A\n",
            "Batches:  24% 48/196 [00:03<00:08, 16.69it/s]\u001b[A\n",
            "Batches:  26% 50/196 [00:03<00:08, 17.04it/s]\u001b[A\n",
            "Batches:  27% 52/196 [00:03<00:08, 16.94it/s]\u001b[A\n",
            "Batches:  28% 54/196 [00:03<00:08, 16.59it/s]\u001b[A\n",
            "Batches:  29% 56/196 [00:04<00:08, 16.81it/s]\u001b[A\n",
            "Batches:  30% 58/196 [00:04<00:08, 16.93it/s]\u001b[A\n",
            "Batches:  31% 60/196 [00:04<00:07, 17.62it/s]\u001b[A\n",
            "Batches:  32% 62/196 [00:04<00:07, 18.13it/s]\u001b[A\n",
            "Batches:  33% 64/196 [00:04<00:07, 18.27it/s]\u001b[A\n",
            "Batches:  34% 66/196 [00:04<00:06, 18.74it/s]\u001b[A\n",
            "Batches:  35% 69/196 [00:04<00:06, 19.51it/s]\u001b[A\n",
            "Batches:  37% 72/196 [00:04<00:06, 20.06it/s]\u001b[A\n",
            "Batches:  38% 75/196 [00:05<00:05, 20.41it/s]\u001b[A\n",
            "Batches:  40% 78/196 [00:05<00:05, 20.40it/s]\u001b[A\n",
            "Batches:  41% 81/196 [00:05<00:05, 20.71it/s]\u001b[A\n",
            "Batches:  43% 84/196 [00:05<00:05, 21.45it/s]\u001b[A\n",
            "Batches:  44% 87/196 [00:05<00:04, 22.02it/s]\u001b[A\n",
            "Batches:  46% 90/196 [00:05<00:04, 21.93it/s]\u001b[A\n",
            "Batches:  47% 93/196 [00:05<00:04, 21.89it/s]\u001b[A\n",
            "Batches:  49% 96/196 [00:06<00:04, 22.51it/s]\u001b[A\n",
            "Batches:  51% 99/196 [00:06<00:04, 22.88it/s]\u001b[A\n",
            "Batches:  52% 102/196 [00:06<00:04, 23.18it/s]\u001b[A\n",
            "Batches:  54% 105/196 [00:06<00:03, 24.00it/s]\u001b[A\n",
            "Batches:  55% 108/196 [00:06<00:03, 24.35it/s]\u001b[A\n",
            "Batches:  57% 111/196 [00:06<00:03, 25.13it/s]\u001b[A\n",
            "Batches:  58% 114/196 [00:06<00:03, 25.44it/s]\u001b[A\n",
            "Batches:  60% 117/196 [00:06<00:03, 25.23it/s]\u001b[A\n",
            "Batches:  61% 120/196 [00:06<00:02, 25.85it/s]\u001b[A\n",
            "Batches:  63% 123/196 [00:07<00:02, 25.63it/s]\u001b[A\n",
            "Batches:  64% 126/196 [00:07<00:02, 26.25it/s]\u001b[A\n",
            "Batches:  66% 129/196 [00:07<00:02, 26.68it/s]\u001b[A\n",
            "Batches:  67% 132/196 [00:07<00:02, 27.21it/s]\u001b[A\n",
            "Batches:  69% 136/196 [00:07<00:02, 28.42it/s]\u001b[A\n",
            "Batches:  71% 139/196 [00:07<00:02, 28.48it/s]\u001b[A\n",
            "Batches:  73% 143/196 [00:07<00:01, 29.20it/s]\u001b[A\n",
            "Batches:  74% 146/196 [00:07<00:01, 28.88it/s]\u001b[A\n",
            "Batches:  77% 150/196 [00:07<00:01, 29.70it/s]\u001b[A\n",
            "Batches:  79% 154/196 [00:08<00:01, 30.46it/s]\u001b[A\n",
            "Batches:  81% 158/196 [00:08<00:01, 30.97it/s]\u001b[A\n",
            "Batches:  83% 162/196 [00:08<00:01, 31.18it/s]\u001b[A\n",
            "Batches:  85% 166/196 [00:08<00:00, 31.53it/s]\u001b[A\n",
            "Batches:  87% 170/196 [00:08<00:00, 31.98it/s]\u001b[A\n",
            "Batches:  89% 174/196 [00:08<00:00, 32.47it/s]\u001b[A\n",
            "Batches:  91% 178/196 [00:08<00:00, 33.99it/s]\u001b[A\n",
            "Batches:  93% 182/196 [00:08<00:00, 34.80it/s]\u001b[A\n",
            "Batches:  95% 186/196 [00:09<00:00, 35.20it/s]\u001b[A\n",
            "Batches:  97% 191/196 [00:09<00:00, 36.75it/s]\u001b[A\n",
            "Batches: 100% 196/196 [00:09<00:00, 21.08it/s]\n",
            "Corpus Chunks: 100% 1/1 [00:09<00:00,  9.58s/it]\n",
            "  Validation NDCG@10: 0.5235\n",
            "  Validation RECALL@10: 0.7462\n",
            "  Validation MRR@10: 0.4537\n",
            "  Saving best model (score: 0.5235)...\n",
            "      ✓ New best score: 0.5235\n",
            "\n",
            "Epoch 6/20\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "{'train_runtime': 169.4081, 'train_samples_per_second': 92.575, 'train_steps_per_second': 2.898, 'train_loss': 0.056467817660019015, 'epoch': 1.0}\n",
            "100% 491/491 [02:49<00:00,  2.90it/s]\n",
            "\n",
            "  Validating...\n",
            "Batches: 100% 123/123 [00:02<00:00, 55.62it/s]\n",
            "Corpus Chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Batches:   0% 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Batches:   1% 2/196 [00:00<00:16, 11.42it/s]\u001b[A\n",
            "Batches:   2% 4/196 [00:00<00:19, 10.02it/s]\u001b[A\n",
            "Batches:   3% 6/196 [00:00<00:19,  9.80it/s]\u001b[A\n",
            "Batches:   4% 8/196 [00:00<00:18, 10.01it/s]\u001b[A\n",
            "Batches:   5% 10/196 [00:01<00:19,  9.39it/s]\u001b[A\n",
            "Batches:   6% 12/196 [00:01<00:18, 10.04it/s]\u001b[A\n",
            "Batches:   7% 14/196 [00:01<00:17, 10.69it/s]\u001b[A\n",
            "Batches:   8% 16/196 [00:01<00:16, 11.10it/s]\u001b[A\n",
            "Batches:   9% 18/196 [00:01<00:14, 11.90it/s]\u001b[A\n",
            "Batches:  10% 20/196 [00:01<00:14, 12.54it/s]\u001b[A\n",
            "Batches:  11% 22/196 [00:01<00:14, 12.33it/s]\u001b[A\n",
            "Batches:  12% 24/196 [00:02<00:13, 12.51it/s]\u001b[A\n",
            "Batches:  13% 26/196 [00:02<00:13, 13.02it/s]\u001b[A\n",
            "Batches:  14% 28/196 [00:02<00:12, 13.47it/s]\u001b[A\n",
            "Batches:  15% 30/196 [00:02<00:11, 14.44it/s]\u001b[A\n",
            "Batches:  16% 32/196 [00:02<00:11, 14.77it/s]\u001b[A\n",
            "Batches:  17% 34/196 [00:02<00:11, 14.53it/s]\u001b[A\n",
            "Batches:  18% 36/196 [00:02<00:10, 14.57it/s]\u001b[A\n",
            "Batches:  19% 38/196 [00:03<00:10, 14.56it/s]\u001b[A\n",
            "Batches:  20% 40/196 [00:03<00:10, 14.83it/s]\u001b[A\n",
            "Batches:  21% 42/196 [00:03<00:10, 15.29it/s]\u001b[A\n",
            "Batches:  22% 44/196 [00:03<00:10, 14.96it/s]\u001b[A\n",
            "Batches:  23% 46/196 [00:03<00:09, 15.84it/s]\u001b[A\n",
            "Batches:  24% 48/196 [00:03<00:08, 16.81it/s]\u001b[A\n",
            "Batches:  26% 50/196 [00:03<00:08, 17.08it/s]\u001b[A\n",
            "Batches:  27% 52/196 [00:03<00:08, 16.75it/s]\u001b[A\n",
            "Batches:  28% 54/196 [00:04<00:08, 16.41it/s]\u001b[A\n",
            "Batches:  29% 56/196 [00:04<00:08, 16.63it/s]\u001b[A\n",
            "Batches:  30% 58/196 [00:04<00:08, 16.93it/s]\u001b[A\n",
            "Batches:  31% 60/196 [00:04<00:07, 17.67it/s]\u001b[A\n",
            "Batches:  32% 62/196 [00:04<00:07, 17.95it/s]\u001b[A\n",
            "Batches:  33% 64/196 [00:04<00:07, 18.51it/s]\u001b[A\n",
            "Batches:  34% 66/196 [00:04<00:06, 18.81it/s]\u001b[A\n",
            "Batches:  35% 69/196 [00:04<00:06, 19.43it/s]\u001b[A\n",
            "Batches:  37% 72/196 [00:04<00:06, 19.84it/s]\u001b[A\n",
            "Batches:  38% 75/196 [00:05<00:05, 20.21it/s]\u001b[A\n",
            "Batches:  40% 78/196 [00:05<00:05, 20.20it/s]\u001b[A\n",
            "Batches:  41% 81/196 [00:05<00:05, 20.79it/s]\u001b[A\n",
            "Batches:  43% 84/196 [00:05<00:05, 21.32it/s]\u001b[A\n",
            "Batches:  44% 87/196 [00:05<00:04, 21.85it/s]\u001b[A\n",
            "Batches:  46% 90/196 [00:05<00:04, 21.71it/s]\u001b[A\n",
            "Batches:  47% 93/196 [00:05<00:04, 21.68it/s]\u001b[A\n",
            "Batches:  49% 96/196 [00:06<00:04, 22.37it/s]\u001b[A\n",
            "Batches:  51% 99/196 [00:06<00:04, 22.73it/s]\u001b[A\n",
            "Batches:  52% 102/196 [00:06<00:04, 22.82it/s]\u001b[A\n",
            "Batches:  54% 105/196 [00:06<00:03, 23.75it/s]\u001b[A\n",
            "Batches:  55% 108/196 [00:06<00:03, 23.91it/s]\u001b[A\n",
            "Batches:  57% 111/196 [00:06<00:03, 25.32it/s]\u001b[A\n",
            "Batches:  58% 114/196 [00:06<00:03, 25.49it/s]\u001b[A\n",
            "Batches:  60% 117/196 [00:06<00:03, 25.54it/s]\u001b[A\n",
            "Batches:  61% 120/196 [00:07<00:02, 25.88it/s]\u001b[A\n",
            "Batches:  63% 123/196 [00:07<00:02, 25.65it/s]\u001b[A\n",
            "Batches:  64% 126/196 [00:07<00:02, 26.43it/s]\u001b[A\n",
            "Batches:  66% 129/196 [00:07<00:02, 26.77it/s]\u001b[A\n",
            "Batches:  67% 132/196 [00:07<00:02, 27.08it/s]\u001b[A\n",
            "Batches:  69% 136/196 [00:07<00:02, 28.16it/s]\u001b[A\n",
            "Batches:  71% 140/196 [00:07<00:01, 29.15it/s]\u001b[A\n",
            "Batches:  73% 143/196 [00:07<00:01, 29.17it/s]\u001b[A\n",
            "Batches:  74% 146/196 [00:07<00:01, 29.32it/s]\u001b[A\n",
            "Batches:  77% 150/196 [00:08<00:01, 29.50it/s]\u001b[A\n",
            "Batches:  79% 154/196 [00:08<00:01, 30.25it/s]\u001b[A\n",
            "Batches:  81% 158/196 [00:08<00:01, 31.04it/s]\u001b[A\n",
            "Batches:  83% 162/196 [00:08<00:01, 30.98it/s]\u001b[A\n",
            "Batches:  85% 166/196 [00:08<00:00, 31.24it/s]\u001b[A\n",
            "Batches:  87% 170/196 [00:08<00:00, 31.96it/s]\u001b[A\n",
            "Batches:  89% 174/196 [00:08<00:00, 32.52it/s]\u001b[A\n",
            "Batches:  91% 178/196 [00:08<00:00, 33.86it/s]\u001b[A\n",
            "Batches:  93% 182/196 [00:09<00:00, 34.56it/s]\u001b[A\n",
            "Batches:  95% 186/196 [00:09<00:00, 35.18it/s]\u001b[A\n",
            "Batches:  97% 190/196 [00:09<00:00, 36.45it/s]\u001b[A\n",
            "Batches: 100% 196/196 [00:09<00:00, 20.93it/s]\n",
            "Corpus Chunks: 100% 1/1 [00:09<00:00,  9.73s/it]\n",
            "  Validation NDCG@10: 0.5261\n",
            "  Validation RECALL@10: 0.7467\n",
            "  Validation MRR@10: 0.4568\n",
            "  Saving best model (score: 0.5261)...\n",
            "      ✓ New best score: 0.5261\n",
            "\n",
            "Epoch 7/20\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "{'train_runtime': 169.5738, 'train_samples_per_second': 92.485, 'train_steps_per_second': 2.895, 'train_loss': 0.04215025659005656, 'epoch': 1.0}\n",
            "100% 491/491 [02:49<00:00,  2.90it/s]\n",
            "\n",
            "  Validating...\n",
            "Batches: 100% 123/123 [00:02<00:00, 57.66it/s]\n",
            "Corpus Chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Batches:   0% 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Batches:   1% 1/196 [00:00<00:24,  7.88it/s]\u001b[A\n",
            "Batches:   2% 3/196 [00:00<00:20,  9.39it/s]\u001b[A\n",
            "Batches:   2% 4/196 [00:00<00:20,  9.50it/s]\u001b[A\n",
            "Batches:   3% 5/196 [00:00<00:20,  9.51it/s]\u001b[A\n",
            "Batches:   4% 7/196 [00:00<00:18, 10.05it/s]\u001b[A\n",
            "Batches:   4% 8/196 [00:00<00:18, 10.00it/s]\u001b[A\n",
            "Batches:   5% 10/196 [00:01<00:19,  9.33it/s]\u001b[A\n",
            "Batches:   6% 12/196 [00:01<00:18, 10.02it/s]\u001b[A\n",
            "Batches:   7% 14/196 [00:01<00:16, 10.86it/s]\u001b[A\n",
            "Batches:   8% 16/196 [00:01<00:16, 11.14it/s]\u001b[A\n",
            "Batches:   9% 18/196 [00:01<00:14, 12.01it/s]\u001b[A\n",
            "Batches:  10% 20/196 [00:01<00:13, 12.63it/s]\u001b[A\n",
            "Batches:  11% 22/196 [00:02<00:14, 12.33it/s]\u001b[A\n",
            "Batches:  12% 24/196 [00:02<00:13, 12.48it/s]\u001b[A\n",
            "Batches:  13% 26/196 [00:02<00:13, 13.02it/s]\u001b[A\n",
            "Batches:  14% 28/196 [00:02<00:12, 13.60it/s]\u001b[A\n",
            "Batches:  15% 30/196 [00:02<00:11, 14.33it/s]\u001b[A\n",
            "Batches:  16% 32/196 [00:02<00:11, 14.82it/s]\u001b[A\n",
            "Batches:  17% 34/196 [00:02<00:11, 14.54it/s]\u001b[A\n",
            "Batches:  18% 36/196 [00:02<00:10, 14.63it/s]\u001b[A\n",
            "Batches:  19% 38/196 [00:03<00:10, 14.58it/s]\u001b[A\n",
            "Batches:  20% 40/196 [00:03<00:10, 14.85it/s]\u001b[A\n",
            "Batches:  21% 42/196 [00:03<00:10, 15.31it/s]\u001b[A\n",
            "Batches:  22% 44/196 [00:03<00:09, 15.71it/s]\u001b[A\n",
            "Batches:  23% 46/196 [00:03<00:09, 15.67it/s]\u001b[A\n",
            "Batches:  24% 48/196 [00:03<00:08, 16.72it/s]\u001b[A\n",
            "Batches:  26% 50/196 [00:03<00:08, 17.06it/s]\u001b[A\n",
            "Batches:  27% 52/196 [00:03<00:08, 16.90it/s]\u001b[A\n",
            "Batches:  28% 54/196 [00:04<00:08, 16.53it/s]\u001b[A\n",
            "Batches:  29% 56/196 [00:04<00:08, 16.63it/s]\u001b[A\n",
            "Batches:  30% 58/196 [00:04<00:08, 16.87it/s]\u001b[A\n",
            "Batches:  31% 60/196 [00:04<00:07, 17.57it/s]\u001b[A\n",
            "Batches:  32% 62/196 [00:04<00:07, 18.19it/s]\u001b[A\n",
            "Batches:  33% 64/196 [00:04<00:07, 18.32it/s]\u001b[A\n",
            "Batches:  34% 66/196 [00:04<00:06, 18.62it/s]\u001b[A\n",
            "Batches:  35% 69/196 [00:04<00:06, 19.53it/s]\u001b[A\n",
            "Batches:  37% 72/196 [00:04<00:06, 19.93it/s]\u001b[A\n",
            "Batches:  38% 75/196 [00:05<00:06, 20.16it/s]\u001b[A\n",
            "Batches:  40% 78/196 [00:05<00:05, 20.33it/s]\u001b[A\n",
            "Batches:  41% 81/196 [00:05<00:05, 20.59it/s]\u001b[A\n",
            "Batches:  43% 84/196 [00:05<00:05, 21.29it/s]\u001b[A\n",
            "Batches:  44% 87/196 [00:05<00:05, 21.78it/s]\u001b[A\n",
            "Batches:  46% 90/196 [00:05<00:04, 21.59it/s]\u001b[A\n",
            "Batches:  47% 93/196 [00:05<00:04, 21.73it/s]\u001b[A\n",
            "Batches:  49% 96/196 [00:06<00:04, 22.16it/s]\u001b[A\n",
            "Batches:  51% 99/196 [00:06<00:04, 22.75it/s]\u001b[A\n",
            "Batches:  52% 102/196 [00:06<00:04, 23.06it/s]\u001b[A\n",
            "Batches:  54% 105/196 [00:06<00:03, 24.22it/s]\u001b[A\n",
            "Batches:  55% 108/196 [00:06<00:03, 24.74it/s]\u001b[A\n",
            "Batches:  57% 111/196 [00:06<00:03, 25.23it/s]\u001b[A\n",
            "Batches:  58% 114/196 [00:06<00:03, 25.33it/s]\u001b[A\n",
            "Batches:  60% 117/196 [00:06<00:03, 25.17it/s]\u001b[A\n",
            "Batches:  61% 120/196 [00:07<00:02, 25.44it/s]\u001b[A\n",
            "Batches:  63% 123/196 [00:07<00:02, 25.34it/s]\u001b[A\n",
            "Batches:  64% 126/196 [00:07<00:02, 26.02it/s]\u001b[A\n",
            "Batches:  66% 129/196 [00:07<00:02, 26.60it/s]\u001b[A\n",
            "Batches:  67% 132/196 [00:07<00:02, 27.12it/s]\u001b[A\n",
            "Batches:  69% 136/196 [00:07<00:02, 28.57it/s]\u001b[A\n",
            "Batches:  71% 139/196 [00:07<00:01, 28.65it/s]\u001b[A\n",
            "Batches:  73% 143/196 [00:07<00:01, 29.16it/s]\u001b[A\n",
            "Batches:  74% 146/196 [00:07<00:01, 29.30it/s]\u001b[A\n",
            "Batches:  77% 150/196 [00:08<00:01, 29.35it/s]\u001b[A\n",
            "Batches:  79% 154/196 [00:08<00:01, 29.98it/s]\u001b[A\n",
            "Batches:  81% 158/196 [00:08<00:01, 30.79it/s]\u001b[A\n",
            "Batches:  83% 162/196 [00:08<00:01, 30.86it/s]\u001b[A\n",
            "Batches:  85% 166/196 [00:08<00:00, 31.44it/s]\u001b[A\n",
            "Batches:  87% 170/196 [00:08<00:00, 32.11it/s]\u001b[A\n",
            "Batches:  89% 174/196 [00:08<00:00, 32.60it/s]\u001b[A\n",
            "Batches:  91% 178/196 [00:08<00:00, 33.91it/s]\u001b[A\n",
            "Batches:  93% 182/196 [00:09<00:00, 34.11it/s]\u001b[A\n",
            "Batches:  95% 186/196 [00:09<00:00, 35.10it/s]\u001b[A\n",
            "Batches:  97% 190/196 [00:09<00:00, 36.38it/s]\u001b[A\n",
            "Batches: 100% 196/196 [00:09<00:00, 20.86it/s]\n",
            "Corpus Chunks: 100% 1/1 [00:09<00:00,  9.74s/it]\n",
            "  Validation NDCG@10: 0.5264\n",
            "  Validation RECALL@10: 0.7485\n",
            "  Validation MRR@10: 0.4566\n",
            "  Saving best model (score: 0.5264)...\n",
            "      No improvement (1/3)\n",
            "\n",
            "Epoch 8/20\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "{'train_runtime': 170.5929, 'train_samples_per_second': 91.932, 'train_steps_per_second': 2.878, 'train_loss': 0.03280655186919234, 'epoch': 1.0}\n",
            "100% 491/491 [02:50<00:00,  2.88it/s]\n",
            "\n",
            "  Validating...\n",
            "Batches: 100% 123/123 [00:02<00:00, 59.75it/s]\n",
            "Corpus Chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Batches:   0% 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Batches:   1% 2/196 [00:00<00:14, 13.30it/s]\u001b[A\n",
            "Batches:   2% 4/196 [00:00<00:19,  9.95it/s]\u001b[A\n",
            "Batches:   3% 6/196 [00:00<00:20,  9.32it/s]\u001b[A\n",
            "Batches:   4% 8/196 [00:00<00:19,  9.56it/s]\u001b[A\n",
            "Batches:   5% 9/196 [00:00<00:20,  9.21it/s]\u001b[A\n",
            "Batches:   5% 10/196 [00:01<00:21,  8.84it/s]\u001b[A\n",
            "Batches:   6% 11/196 [00:01<00:20,  9.11it/s]\u001b[A\n",
            "Batches:   7% 13/196 [00:01<00:17, 10.20it/s]\u001b[A\n",
            "Batches:   8% 15/196 [00:01<00:17, 10.44it/s]\u001b[A\n",
            "Batches:   9% 17/196 [00:01<00:16, 10.72it/s]\u001b[A\n",
            "Batches:  10% 19/196 [00:01<00:15, 11.42it/s]\u001b[A\n",
            "Batches:  11% 21/196 [00:02<00:15, 11.18it/s]\u001b[A\n",
            "Batches:  12% 23/196 [00:02<00:15, 11.39it/s]\u001b[A\n",
            "Batches:  13% 25/196 [00:02<00:14, 12.21it/s]\u001b[A\n",
            "Batches:  14% 27/196 [00:02<00:13, 12.82it/s]\u001b[A\n",
            "Batches:  15% 29/196 [00:02<00:12, 13.16it/s]\u001b[A\n",
            "Batches:  16% 31/196 [00:02<00:11, 13.75it/s]\u001b[A\n",
            "Batches:  17% 33/196 [00:02<00:12, 13.00it/s]\u001b[A\n",
            "Batches:  18% 35/196 [00:03<00:12, 13.09it/s]\u001b[A\n",
            "Batches:  19% 37/196 [00:03<00:11, 13.68it/s]\u001b[A\n",
            "Batches:  20% 39/196 [00:03<00:11, 13.62it/s]\u001b[A\n",
            "Batches:  21% 41/196 [00:03<00:10, 14.22it/s]\u001b[A\n",
            "Batches:  22% 43/196 [00:03<00:10, 14.63it/s]\u001b[A\n",
            "Batches:  23% 45/196 [00:03<00:10, 14.27it/s]\u001b[A\n",
            "Batches:  24% 47/196 [00:03<00:10, 14.56it/s]\u001b[A\n",
            "Batches:  25% 49/196 [00:04<00:09, 14.76it/s]\u001b[A\n",
            "Batches:  26% 51/196 [00:04<00:09, 15.05it/s]\u001b[A\n",
            "Batches:  27% 53/196 [00:04<00:09, 15.43it/s]\u001b[A\n",
            "Batches:  28% 55/196 [00:04<00:09, 15.13it/s]\u001b[A\n",
            "Batches:  29% 57/196 [00:04<00:08, 15.83it/s]\u001b[A\n",
            "Batches:  30% 59/196 [00:04<00:08, 16.18it/s]\u001b[A\n",
            "Batches:  31% 61/196 [00:04<00:08, 16.44it/s]\u001b[A\n",
            "Batches:  32% 63/196 [00:04<00:08, 16.41it/s]\u001b[A\n",
            "Batches:  33% 65/196 [00:04<00:07, 16.39it/s]\u001b[A\n",
            "Batches:  34% 67/196 [00:05<00:07, 16.75it/s]\u001b[A\n",
            "Batches:  35% 69/196 [00:05<00:07, 17.46it/s]\u001b[A\n",
            "Batches:  37% 72/196 [00:05<00:06, 18.53it/s]\u001b[A\n",
            "Batches:  38% 74/196 [00:05<00:06, 18.88it/s]\u001b[A\n",
            "Batches:  39% 77/196 [00:05<00:06, 19.38it/s]\u001b[A\n",
            "Batches:  40% 79/196 [00:05<00:06, 19.17it/s]\u001b[A\n",
            "Batches:  41% 81/196 [00:05<00:05, 19.37it/s]\u001b[A\n",
            "Batches:  42% 83/196 [00:05<00:05, 19.53it/s]\u001b[A\n",
            "Batches:  44% 86/196 [00:06<00:05, 19.88it/s]\u001b[A\n",
            "Batches:  45% 88/196 [00:06<00:05, 19.37it/s]\u001b[A\n",
            "Batches:  46% 91/196 [00:06<00:05, 19.83it/s]\u001b[A\n",
            "Batches:  48% 94/196 [00:06<00:04, 20.82it/s]\u001b[A\n",
            "Batches:  49% 97/196 [00:06<00:04, 21.09it/s]\u001b[A\n",
            "Batches:  51% 100/196 [00:06<00:04, 21.10it/s]\u001b[A\n",
            "Batches:  53% 103/196 [00:06<00:04, 21.56it/s]\u001b[A\n",
            "Batches:  54% 106/196 [00:06<00:04, 22.06it/s]\u001b[A\n",
            "Batches:  56% 109/196 [00:07<00:03, 22.24it/s]\u001b[A\n",
            "Batches:  57% 112/196 [00:07<00:03, 22.87it/s]\u001b[A\n",
            "Batches:  59% 115/196 [00:07<00:03, 23.11it/s]\u001b[A\n",
            "Batches:  60% 118/196 [00:07<00:03, 23.54it/s]\u001b[A\n",
            "Batches:  62% 121/196 [00:07<00:03, 23.97it/s]\u001b[A\n",
            "Batches:  63% 124/196 [00:07<00:02, 24.34it/s]\u001b[A\n",
            "Batches:  65% 127/196 [00:07<00:02, 24.44it/s]\u001b[A\n",
            "Batches:  66% 130/196 [00:07<00:02, 24.56it/s]\u001b[A\n",
            "Batches:  68% 133/196 [00:08<00:02, 25.06it/s]\u001b[A\n",
            "Batches:  69% 136/196 [00:08<00:02, 25.96it/s]\u001b[A\n",
            "Batches:  71% 139/196 [00:08<00:02, 25.96it/s]\u001b[A\n",
            "Batches:  72% 142/196 [00:08<00:02, 26.59it/s]\u001b[A\n",
            "Batches:  74% 145/196 [00:08<00:01, 26.96it/s]\u001b[A\n",
            "Batches:  76% 149/196 [00:08<00:01, 27.94it/s]\u001b[A\n",
            "Batches:  78% 152/196 [00:08<00:01, 27.96it/s]\u001b[A\n",
            "Batches:  79% 155/196 [00:08<00:01, 27.47it/s]\u001b[A\n",
            "Batches:  81% 159/196 [00:09<00:01, 28.77it/s]\u001b[A\n",
            "Batches:  83% 162/196 [00:09<00:01, 28.51it/s]\u001b[A\n",
            "Batches:  85% 166/196 [00:09<00:01, 29.08it/s]\u001b[A\n",
            "Batches:  87% 170/196 [00:09<00:00, 29.53it/s]\u001b[A\n",
            "Batches:  88% 173/196 [00:09<00:00, 29.49it/s]\u001b[A\n",
            "Batches:  90% 177/196 [00:09<00:00, 31.14it/s]\u001b[A\n",
            "Batches:  92% 181/196 [00:09<00:00, 32.60it/s]\u001b[A\n",
            "Batches:  94% 185/196 [00:09<00:00, 31.92it/s]\u001b[A\n",
            "Batches:  96% 189/196 [00:09<00:00, 33.21it/s]\u001b[A\n",
            "Batches: 100% 196/196 [00:10<00:00, 19.34it/s]\n",
            "Corpus Chunks: 100% 1/1 [00:10<00:00, 10.53s/it]\n",
            "  Validation NDCG@10: 0.5237\n",
            "  Validation RECALL@10: 0.7442\n",
            "  Validation MRR@10: 0.4544\n",
            "      No improvement (2/3)\n",
            "\n",
            "Epoch 9/20\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "{'train_runtime': 173.3039, 'train_samples_per_second': 90.494, 'train_steps_per_second': 2.833, 'train_loss': 0.025879516135408048, 'epoch': 1.0}\n",
            "100% 491/491 [02:53<00:00,  2.83it/s]\n",
            "\n",
            "  Validating...\n",
            "Batches: 100% 123/123 [00:01<00:00, 80.03it/s]\n",
            "Corpus Chunks:   0% 0/1 [00:00<?, ?it/s]\n",
            "Batches:   0% 0/196 [00:00<?, ?it/s]\u001b[A\n",
            "Batches:   1% 2/196 [00:00<00:14, 13.51it/s]\u001b[A\n",
            "Batches:   2% 4/196 [00:00<00:18, 10.17it/s]\u001b[A\n",
            "Batches:   3% 6/196 [00:00<00:19,  9.60it/s]\u001b[A\n",
            "Batches:   4% 8/196 [00:00<00:19,  9.66it/s]\u001b[A\n",
            "Batches:   5% 9/196 [00:00<00:19,  9.66it/s]\u001b[A\n",
            "Batches:   5% 10/196 [00:01<00:20,  8.88it/s]\u001b[A\n",
            "Batches:   6% 12/196 [00:01<00:19,  9.63it/s]\u001b[A\n",
            "Batches:   7% 14/196 [00:01<00:17, 10.40it/s]\u001b[A\n",
            "Batches:   8% 16/196 [00:01<00:16, 10.68it/s]\u001b[A\n",
            "Batches:   9% 18/196 [00:01<00:15, 11.50it/s]\u001b[A\n",
            "Batches:  10% 20/196 [00:01<00:15, 11.62it/s]\u001b[A\n",
            "Batches:  11% 22/196 [00:02<00:15, 11.52it/s]\u001b[A\n",
            "Batches:  12% 24/196 [00:02<00:14, 11.98it/s]\u001b[A\n",
            "Batches:  13% 26/196 [00:02<00:13, 12.49it/s]\u001b[A\n",
            "Batches:  14% 28/196 [00:02<00:12, 13.07it/s]\u001b[A\n",
            "Batches:  15% 30/196 [00:02<00:12, 13.53it/s]\u001b[A\n",
            "Batches:  16% 32/196 [00:02<00:11, 14.16it/s]\u001b[A\n",
            "Batches:  17% 34/196 [00:02<00:11, 13.55it/s]\u001b[A\n",
            "Batches:  18% 36/196 [00:03<00:11, 13.74it/s]\u001b[A\n",
            "Batches:  19% 38/196 [00:03<00:11, 14.09it/s]\u001b[A\n",
            "Batches:  20% 40/196 [00:03<00:10, 14.42it/s]\u001b[A\n",
            "Batches:  21% 42/196 [00:03<00:10, 14.81it/s]\u001b[A\n",
            "Batches:  22% 44/196 [00:03<00:10, 15.00it/s]\u001b[A\n",
            "Batches:  23% 46/196 [00:03<00:10, 14.96it/s]\u001b[A\n",
            "Batches:  24% 48/196 [00:03<00:09, 15.60it/s]\u001b[A\n",
            "Batches:  26% 50/196 [00:03<00:09, 15.58it/s]\u001b[A\n",
            "Batches:  27% 52/196 [00:04<00:09, 15.61it/s]\u001b[A\n",
            "Batches:  28% 54/196 [00:04<00:09, 15.67it/s]\u001b[A\n",
            "Batches:  29% 56/196 [00:04<00:08, 16.08it/s]\u001b[A\n",
            "Batches:  30% 58/196 [00:04<00:08, 16.26it/s]\u001b[A\n",
            "Batches:  31% 60/196 [00:04<00:08, 16.87it/s]\u001b[A\n",
            "Batches:  32% 62/196 [00:04<00:07, 17.34it/s]\u001b[A\n",
            "Batches:  33% 64/196 [00:04<00:07, 17.18it/s]\u001b[A\n",
            "Batches:  34% 66/196 [00:04<00:07, 17.20it/s]\u001b[A\n",
            "Batches:  35% 68/196 [00:05<00:07, 17.60it/s]\u001b[A\n",
            "Batches:  36% 71/196 [00:05<00:06, 18.63it/s]\u001b[A\n",
            "Batches:  37% 73/196 [00:05<00:06, 18.98it/s]\u001b[A\n",
            "Batches:  39% 76/196 [00:05<00:06, 19.62it/s]\u001b[A\n",
            "Batches:  40% 78/196 [00:05<00:06, 19.39it/s]\u001b[A\n",
            "Batches:  41% 81/196 [00:05<00:05, 20.17it/s]\u001b[A\n",
            "Batches:  43% 84/196 [00:05<00:05, 20.01it/s]\u001b[A\n",
            "Batches:  44% 87/196 [00:05<00:05, 20.38it/s]\u001b[A\n",
            "Batches:  46% 90/196 [00:06<00:05, 19.67it/s]\u001b[A\n",
            "Batches:  47% 93/196 [00:06<00:04, 20.68it/s]\u001b[A\n",
            "Batches:  49% 96/196 [00:06<00:04, 21.41it/s]\u001b[A\n",
            "Batches:  51% 99/196 [00:06<00:04, 22.00it/s]\u001b[A\n",
            "Batches:  52% 102/196 [00:06<00:04, 22.25it/s]\u001b[A\n",
            "Batches:  54% 105/196 [00:06<00:04, 22.74it/s]\u001b[A\n",
            "Batches:  55% 108/196 [00:06<00:03, 23.20it/s]\u001b[A\n",
            "Batches:  57% 111/196 [00:06<00:03, 23.42it/s]\u001b[A\n",
            "Batches:  58% 114/196 [00:07<00:03, 23.50it/s]\u001b[A\n",
            "Batches:  60% 117/196 [00:07<00:03, 23.97it/s]\u001b[A\n",
            "Batches:  61% 120/196 [00:07<00:03, 24.40it/s]\u001b[A\n",
            "Batches:  63% 123/196 [00:07<00:02, 25.11it/s]\u001b[A\n",
            "Batches:  64% 126/196 [00:07<00:02, 25.75it/s]\u001b[A\n",
            "Batches:  66% 129/196 [00:07<00:02, 25.94it/s]\u001b[A\n",
            "Batches:  67% 132/196 [00:07<00:02, 25.95it/s]\u001b[A\n",
            "Batches:  69% 135/196 [00:07<00:02, 26.62it/s]\u001b[A\n",
            "Batches:  70% 138/196 [00:08<00:02, 27.04it/s]\u001b[A\n",
            "Batches:  72% 141/196 [00:08<00:02, 27.04it/s]\u001b[A\n",
            "Batches:  74% 145/196 [00:08<00:01, 28.12it/s]\u001b[A\n",
            "Batches:  76% 149/196 [00:08<00:01, 28.58it/s]\u001b[A\n",
            "Batches:  78% 152/196 [00:08<00:01, 28.23it/s]\u001b[A\n",
            "Batches:  80% 156/196 [00:08<00:01, 28.99it/s]\u001b[A\n",
            "Batches:  82% 160/196 [00:08<00:01, 29.99it/s]\u001b[A\n",
            "Batches:  83% 163/196 [00:08<00:01, 29.09it/s]\u001b[A\n",
            "Batches:  85% 167/196 [00:09<00:00, 29.58it/s]\u001b[A\n",
            "Batches:  87% 171/196 [00:09<00:00, 30.15it/s]\u001b[A\n",
            "Batches:  89% 175/196 [00:09<00:00, 30.87it/s]\u001b[A\n",
            "Batches:  92% 180/196 [00:09<00:00, 33.67it/s]\u001b[A\n",
            "Batches:  94% 184/196 [00:09<00:00, 33.59it/s]\u001b[A\n",
            "Batches:  96% 188/196 [00:09<00:00, 34.58it/s]\u001b[A\n",
            "Batches:  98% 192/196 [00:09<00:00, 35.48it/s]\u001b[A\n",
            "Batches: 100% 196/196 [00:09<00:00, 19.96it/s]\n",
            "Corpus Chunks: 100% 1/1 [00:10<00:00, 10.11s/it]\n",
            "  Validation NDCG@10: 0.5216\n",
            "  Validation RECALL@10: 0.7434\n",
            "  Validation MRR@10: 0.4518\n",
            "      No improvement (3/3)\n",
            "\n",
            "      Early stopping triggered at epoch 9\n",
            "------------------------------------------------------------\n",
            "Training completed at: 2025-11-20 04:13:47\n",
            "Best validation score: 0.5264\n",
            "Model saved to: /content/drive/MyDrive/ML-for-context/models/ultimate\n",
            "Training history saved to: ./training_history.json\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!python -m src.training.train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y protobuf\n",
        "!pip install protobuf==3.20.3\n",
        "\n",
        "import importlib\n",
        "import sys\n",
        "if 'google.protobuf' in sys.modules:\n",
        "    importlib.reload(sys.modules['google.protobuf'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "bLNvN6uffXik",
        "outputId": "87a89b9d-16e2-4143-b613-36f4a8b9c271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: protobuf 6.32.1\n",
            "Uninstalling protobuf-6.32.1:\n",
            "  Successfully uninstalled protobuf-6.32.1\n",
            "Collecting protobuf==3.20.3\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "d31900b7d16f4bc28759fc26931cb540"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFeDZ76XYdV-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "57fa26f9-43d8-4fd4-dca4-2b5299323c23"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "import os\n",
        "os.environ[\"PYTHONUNBUFFERED\"] = \"1\"\n",
        "\n",
        "from src.evaluation import evaluate\n",
        "\n",
        "import argparse\n",
        "sys.argv = ['evaluate.py', '--model', '/content/drive/MyDrive/ML-for-context/models/ultimate']\n",
        "\n",
        "evaluate.main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"src/bonus/analyze_embeddings.py\", \"r\") as f:\n",
        "    content = f.read()\n",
        "\n",
        "content = content.replace(\n",
        "    \"with open('cache/embeddings/embeddings_finetuned_normalized.pkl.npz', 'rb') as f:\",\n",
        "    \"with open('/content/drive/MyDrive/ML-for-context/cache-ultimate/embeddings/embeddings_e53b839d_normalized.pkl.npz', 'rb') as f:\"\n",
        ")\n",
        "\n",
        "with open(\"src/bonus/analyze_embeddings.py\", \"w\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"✓ Updated analyze_embeddings.py to use cache-ultimate\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfFeaEqFfStA",
        "outputId": "388a47a5-1c65-4ca7-b1a9-f5e59e9193ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Updated analyze_embeddings.py to use cache-ultimate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cache_dir = \"/content/drive/MyDrive/ML-for-context/cache-ultimate/embeddings/\"\n",
        "print(f\"Directory exists: {os.path.exists(cache_dir)}\")\n",
        "if os.path.exists(cache_dir):\n",
        "    files = os.listdir(cache_dir)\n",
        "    print(f\"Files found: {files}\")\n",
        "else:\n",
        "    print(\"Directory doesn't exist! Evaluate hasn't created the cache yet.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I5W09fUglYd",
        "outputId": "90202bc2-4420-4302-fa61-ae8859bc71fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory exists: True\n",
            "Files found: ['embeddings_e53b839d_normalized.pkl.npz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.training.plot_training --history /content/drive/MyDrive/ML-for-context/training_history.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGMhM0lvREiK",
        "outputId": "8c43cc53-6d47-4158-9970-5d0ed0eac151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-20 12:38:58.019225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763642338.050998    1287 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763642338.060588    1287 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763642338.084839    1287 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763642338.084867    1287 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763642338.084875    1287 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763642338.084881    1287 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-20 12:38:58.092531: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/ML-for-context/src/training/plot_training.py\", line 53, in <module>\n",
            "    plot_training_history(args.history)\n",
            "  File \"/content/ML-for-context/src/training/plot_training.py\", line 7, in plot_training_history\n",
            "    with open(history_path, 'r') as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML-for-context/training_history.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"src/bonus/analyze_embeddings.py\", \"r\") as f:\n",
        "    content = f.read()\n",
        "\n",
        "content = content.replace(\n",
        "    \"with open('/content/drive/MyDrive/ML-for-context/cache-ultimate/embeddings/embeddings_finetuned_normalized.pkl.npz', 'rb') as f:\",\n",
        "    \"with open('/content/drive/MyDrive/ML-for-context/cache-ultimate/embeddings/embeddings_e53b839d_normalized.pkl.npz', 'rb') as f:\"\n",
        ")\n",
        "\n",
        "with open(\"src/bonus/analyze_embeddings.py\", \"w\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"✓ Fixed filename\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PriJbiK5hEhI",
        "outputId": "c5a5fb35-cb8d-4aaa-e38c-241905c1f3cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Fixed filename\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "_GIOOaNthHRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBzqCK7tdFco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fa2f23-a864-4588-b909-ad4941332de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ANALYZING EMBEDDINGS STRUCTURE\n",
            "============================================================\n",
            "\n",
            "[1/3] Loading embeddings from cache...\n",
            "      Shape: (6267, 768)\n",
            "      Total values: 4,813,056\n",
            "\n",
            "[2/3] Sparsity Analysis:\n",
            "------------------------------------------------------------\n",
            "  Exact zeros (= 0):        0 (0.0000%)\n",
            "  Near-zero (< 0.001):      108,970 (2.2641%)\n",
            "  Near-zero (< 0.01):       1,072,736 (22.2880%)\n",
            "  Near-zero (< 0.05):       4,033,531 (83.8039%)\n",
            "\n",
            "  Value Statistics:\n",
            "    Min:    -0.342605\n",
            "    Max:    0.393488\n",
            "    Mean:   0.001166\n",
            "    Std:    0.036066\n",
            "    Median: 0.001079\n",
            "\n",
            "  Per-document zeros:\n",
            "    Mean:   0.00 / 768\n",
            "    Min:    0 / 768\n",
            "    Max:    0 / 768\n",
            "\n",
            "[3/3] Intrinsic Dimensionality:\n",
            "------------------------------------------------------------\n",
            "  Computing PCA ...\n",
            "\n",
            "  Dimensions needed to explain variance:\n",
            "    50% variance:  34 / 768 (4.4%)\n",
            "    90% variance: 245 / 768 (31.9%)\n",
            "    95% variance: 367 / 768 (47.8%)\n",
            "    99% variance: 600 / 768 (78.1%)\n",
            "\n",
            "  Top 10 components explain: 23.05% of variance\n",
            "  Top 50 components explain: 59.28% of variance\n",
            "\n",
            "Value Distribution:\n",
            "------------------------------------------------------------\n",
            "  < -0.1         :     13,551 ( 0.28%)\n",
            "  [-0.1, -0.05)  :    352,618 ( 7.33%)\n",
            "  [-0.05, -0.01) :  1,447,503 (30.07%)\n",
            "  [-0.01, 0)     :    533,944 (11.09%)\n",
            "  [0, 0.01)      :    538,793 (11.19%)\n",
            "  [0.01, 0.05)   :  1,513,291 (31.44%)\n",
            "  [0.05, 0.1)    :    395,241 ( 8.21%)\n",
            "  >= 0.1         :     18,115 ( 0.38%)\n",
            "\n",
            "============================================================\n",
            "ANALYSIS COMPLETE\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!python -m src.bonus.analyze_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"src/bonus/test_pca_whitening.py\", \"r\") as f:\n",
        "    content = f.read()\n",
        "\n",
        "content = content.replace(\n",
        "    \"with open('./cache/embeddings/embeddings_finetuned_normalized.pkl.npz', 'rb') as f:\",\n",
        "    \"with open('/content/drive/MyDrive/ML-for-context/cache-ultimate/embeddings/embeddings_e53b839d_normalized.pkl.npz', 'rb') as f:\"\n",
        ")\n",
        "\n",
        "content = content.replace(\n",
        "    'model_name=\"./models/unixcoder-finetuned\"',\n",
        "    'model_name=\"/content/drive/MyDrive/ML-for-context/models/ultimate\"'\n",
        ")\n",
        "\n",
        "with open(\"src/bonus/test_pca_whitening.py\", \"w\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"✓ Updated paths for Colab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNABpgyci2SX",
        "outputId": "70641772-f20c-412f-8073-493832df07cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Updated paths for Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"src/bonus/test_pca_whitening.py\", \"r\") as f:\n",
        "    content = f.read()\n",
        "\n",
        "new_content = \"\"\"import pickle\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, '.')\n",
        "from src.embeddings import EmbeddingModel\n",
        "from src.evaluation.cosqa_loader import CoSQALoader\n",
        "from src.evaluation.evaluate import deduplicate_evaluation\n",
        "\n",
        "print(\"Loading test set...\")\n",
        "loader = CoSQALoader()\n",
        "corpus_orig, queries, relevance_orig = loader.load(split='test')\n",
        "\n",
        "print(\"Deduplicating...\")\n",
        "corpus, queries, relevance = deduplicate_evaluation(corpus_orig, queries, relevance_orig)\n",
        "print(f\"Loaded {len(corpus)} documents (deduplicated) and {len(queries)} queries\")\n",
        "\n",
        "print(\"\\\\nLoading cached embeddings...\")\n",
        "with open('/content/drive/MyDrive/ML-for-context/cache-ultimate/embeddings/embeddings_e53b839d_normalized.pkl.npz', 'rb') as f:\n",
        "    embeddings = pickle.load(f)\n",
        "\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "\n",
        "print(\"\\\\nComputing PCA...\")\n",
        "pca = PCA()\n",
        "pca_embeddings = pca.fit_transform(embeddings)\n",
        "pca_embeddings = pca_embeddings / np.linalg.norm(pca_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "print(\"Computing PCA whitening...\")\n",
        "pca_whitened = PCA(whiten=True)\n",
        "pca_whitened_embeddings = pca_whitened.fit_transform(embeddings)\n",
        "pca_whitened_embeddings = pca_whitened_embeddings / np.linalg.norm(pca_whitened_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "print(\"\\\\nLoading model for query encoding...\")\n",
        "model = EmbeddingModel(\n",
        "    model_name=\"/content/drive/MyDrive/ML-for-context/models/ultimate\",\n",
        "    max_seq_length=256,\n",
        "    device=None\n",
        ")\n",
        "\n",
        "def process_queries_and_compute_metrics(queries, corpus_embeddings, query_transform_fn, metric_type='cosine'):\n",
        "    recalls = []\n",
        "    mrrs = []\n",
        "    ndcgs = []\n",
        "\n",
        "    for query in queries:\n",
        "        query_id = query[\"query_id\"]\n",
        "        query_text = query[\"query_text\"]\n",
        "        relevant_indices = relevance[query_id]\n",
        "\n",
        "        query_embedding = model.encode(query_text, batch_size=1, show_progress_bar=False)\n",
        "\n",
        "        if query_transform_fn is not None:\n",
        "            query_embedding = query_transform_fn(query_embedding.reshape(1, -1))\n",
        "            query_embedding = query_embedding.flatten()\n",
        "            query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
        "        else:\n",
        "            query_embedding = query_embedding.flatten()\n",
        "\n",
        "        if metric_type == 'cosine':\n",
        "            scores = np.dot(corpus_embeddings, query_embedding)\n",
        "            top_indices = np.argsort(scores)[-10:][::-1]\n",
        "        else:\n",
        "            distances = np.sum(np.abs(corpus_embeddings - query_embedding), axis=1)\n",
        "            top_indices = np.argsort(distances)[:10]\n",
        "\n",
        "        retrieved = top_indices.tolist()\n",
        "        relevant_set = set(relevant_indices)\n",
        "        retrieved_set = set(retrieved[:10])\n",
        "\n",
        "        recalls.append(len(retrieved_set & relevant_set) / len(relevant_set) if relevant_set else 0)\n",
        "\n",
        "        for i, doc_idx in enumerate(retrieved[:10], 1):\n",
        "            if doc_idx in relevant_set:\n",
        "                mrrs.append(1.0 / i)\n",
        "                break\n",
        "        else:\n",
        "            mrrs.append(0.0)\n",
        "\n",
        "        dcg = 0\n",
        "        for i, doc_idx in enumerate(retrieved[:10], 1):\n",
        "            if doc_idx in relevant_set:\n",
        "                dcg += 1.0 / np.log2(i + 1)\n",
        "\n",
        "        idcg = 0\n",
        "        for i in range(1, min(len(relevant_set), 10) + 1):\n",
        "            idcg += 1.0 / np.log2(i + 1)\n",
        "\n",
        "        ndcgs.append(dcg / idcg if idcg > 0 else 0)\n",
        "\n",
        "    return (\n",
        "        sum(mrrs) / len(mrrs),\n",
        "        sum(recalls) / len(recalls),\n",
        "        sum(ndcgs) / len(ndcgs)\n",
        "    )\n",
        "\n",
        "print(\"\\\\nComputing baseline metrics...\")\n",
        "baseline_cosine = process_queries_and_compute_metrics(queries, embeddings, None, 'cosine')\n",
        "baseline_manhattan = process_queries_and_compute_metrics(queries, embeddings, None, 'manhattan')\n",
        "\n",
        "print(\"Computing PCA metrics...\")\n",
        "pca_cosine = process_queries_and_compute_metrics(queries, pca_embeddings, pca.transform, 'cosine')\n",
        "pca_manhattan = process_queries_and_compute_metrics(queries, pca_embeddings, pca.transform, 'manhattan')\n",
        "\n",
        "print(\"Computing whitened metrics...\")\n",
        "whitened_cosine = process_queries_and_compute_metrics(queries, pca_whitened_embeddings, pca_whitened.transform, 'cosine')\n",
        "whitened_manhattan = process_queries_and_compute_metrics(queries, pca_whitened_embeddings, pca_whitened.transform, 'manhattan')\n",
        "\n",
        "results = {\n",
        "    'baseline': {\n",
        "        'cosine': baseline_cosine,\n",
        "        'manhattan': baseline_manhattan\n",
        "    },\n",
        "    'pca': {\n",
        "        'cosine': pca_cosine,\n",
        "        'manhattan': pca_manhattan\n",
        "    },\n",
        "    'whitened': {\n",
        "        'cosine': whitened_cosine,\n",
        "        'manhattan': whitened_manhattan\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\\\n\\\\nRESULTS ON TEST SET:\")\n",
        "print(\"=\"*60)\n",
        "for method in ['baseline', 'pca', 'whitened']:\n",
        "    print(f\"\\\\n{method.upper()}:\")\n",
        "    for metric in ['cosine', 'manhattan']:\n",
        "        mrr, recall, ndcg = results[method][metric]\n",
        "        print(f\"  {metric}:\")\n",
        "        print(f\"    MRR@10:    {mrr:.4f}\")\n",
        "        print(f\"    Recall@10: {recall:.4f}\")\n",
        "        print(f\"    NDCG@10:   {ndcg:.4f}\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"src/bonus/test_pca_whitening.py\", \"w\") as f:\n",
        "    f.write(new_content)\n",
        "\n",
        "print(\"✓ Updated test_pca_whitening.py with deduplication and correct paths\")\n",
        "\n",
        "import os\n",
        "os.system(\"python -m src.bonus.test_pca_whitening\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU6peiqWjYIw",
        "outputId": "55b2186e-c94e-42f6-f057-d7af137c7ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Updated test_pca_whitening.py with deduplication and correct paths\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.bonus.test_pca_whitening"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMQJTOaLj_75",
        "outputId": "62e68a7b-30a0-4ecf-e4f1-77f7d9e1babc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-20 04:40:15.649811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763613615.671606   21808 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763613615.677810   21808 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763613615.693078   21808 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763613615.693103   21808 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763613615.693107   21808 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763613615.693110   21808 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-20 04:40:15.697726: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Loading test set...\n",
            "Deduplicating...\n",
            "Loaded 6267 documents (deduplicated) and 500 queries\n",
            "\n",
            "Loading cached embeddings...\n",
            "Embeddings shape: (6267, 768)\n",
            "\n",
            "Computing PCA...\n",
            "Computing PCA whitening...\n",
            "\n",
            "Loading model for query encoding...\n",
            "\n",
            "Computing baseline metrics...\n",
            "Computing PCA metrics...\n",
            "Computing whitened metrics...\n",
            "\n",
            "\n",
            "RESULTS ON TEST SET:\n",
            "============================================================\n",
            "\n",
            "BASELINE:\n",
            "  cosine:\n",
            "    MRR@10:    0.4791\n",
            "    Recall@10: 0.7560\n",
            "    NDCG@10:   0.5452\n",
            "  manhattan:\n",
            "    MRR@10:    0.4793\n",
            "    Recall@10: 0.7480\n",
            "    NDCG@10:   0.5438\n",
            "\n",
            "PCA:\n",
            "  cosine:\n",
            "    MRR@10:    0.4793\n",
            "    Recall@10: 0.7560\n",
            "    NDCG@10:   0.5454\n",
            "  manhattan:\n",
            "    MRR@10:    0.4777\n",
            "    Recall@10: 0.7560\n",
            "    NDCG@10:   0.5443\n",
            "\n",
            "WHITENED:\n",
            "  cosine:\n",
            "    MRR@10:    0.4772\n",
            "    Recall@10: 0.7500\n",
            "    NDCG@10:   0.5428\n",
            "  manhattan:\n",
            "    MRR@10:    0.4702\n",
            "    Recall@10: 0.7380\n",
            "    NDCG@10:   0.5348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('/content')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PXPeoNf5n-W",
        "outputId": "aa261fc3-bbf1-4793-b7f0-d5c0288d5f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}